{
  "hash": "e3db3faa1be997c98a1ba6e6d42dccba",
  "result": {
    "engine": "knitr",
    "markdown": "# Analyses d'évènements localisés sur un réseau {#sec-chap06}\n\nDans le [chapitre @sec-chap03], nous avons décrit des méthodes de répartition ponctuelle qui s'appliquent à des espaces classiques en deux dimensions, homogènes et sans limites dans toutes les directions. Par contre, lorsque les évènements (points) ne peuvent se produire que le long des lignes d'un réseau, les hypothèses de base des méthodes de répartition ponctuelle ne tiennent plus et produisent alors des résultats biaisés. Par conséquent, dans ce chapitre, nous abordons des méthodes d'analyse de répartition ponctuelle spécifiques à des évènements localisés sur un réseau.\n\n::: bloc_package\n::: bloc_package-header\n::: bloc_package-icon\n:::\n\n**Liste des *packages* utilisés dans ce chapitre**\n:::\n\n::: bloc_package-body\n-   Pour importer et manipuler des fichiers géographiques :\n    -   `sf` pour importer et manipuler des données vectorielles.\n    -   `lubridate` pour manipuler des champs de format date.\n-   Pour construire des cartes et des graphiques :\n    -   `tmap` pour construire des cartes thématiques.\n    -   `ggplot2` pour construire des graphiques.\n    -   `classInt` pour définir des intervalles sur une variable continue.\n    -   `viridis` pour des palettes de couleurs.\n-   Pour les analyses de méthodes de répartition ponctuelle sur un réseau :\n    -   `spNetwork` dédié aux analyses spatiales sur un réseau.\n    -   `future` pour accélérer les calculs de `spNetwork`.\n    -   `spdep` pour calculer des indices d'autocorrélation spatiale.\n    -   `dbscan` pour l'algorithme DBSCAN.\n:::\n:::\n\n## Pourquoi recourir à un réseau pour des méthodes d'analyse de répartition ponctuelle? {#sec-061}\n\nLes méthodes classiques d'analyse de répartition ponctuelle postulent que l'espace analysé est le plus souvent en deux dimensions, homogène et sans limite dans toutes les directions. Toutefois, des phénomènes se produisent dans des espaces pour lesquels ces hypothèses sont totalement invalidées, menant à l'obtention de résultats biaisés, voire incohérents. C'est notamment le cas d'évènements localisés le long des segments d'un réseau qui sont par exemple :\n\n-   Des accidents de la route se produisent nécessairement le long des axes routiers.\n\n-   Des fuites d'eau se produisent le long des canalisations d'une ville.\n\n-   Des interruptions de service de bus se produisent le long de lignes de transport collectif.\n\n-   Certaines espèces d'oiseaux nichent systématiquement le long de cours d'eau.\n\nContrairement à un espace géographique classique en deux dimensions, il est possible de considérer qu'un réseau géographique (c'est-à-dire un réseau dont les nœuds et les lignes ont des coordonnées spatiales) est un espace en 1,5 dimension puisqu'il n'est possible de se déplacer que le long des lignes et de ne changer de direction qu'au niveau d'un nœud [@steenberghen2010spatial]. Cette distinction pose trois problèmes principaux si nous utilisons les méthodes de répartition ponctuelle classiques.\n\nPremièrement, la distance euclidienne (à vol d'oiseau) tend systématiquement à sous-estimer la distance réelle entre deux points. En effet, la longueur d'un trajet sur un réseau est toujours plus grande ou égale à la distance euclidienne. La @fig-illusAnalyseReseauA illustre ce premier problème avec un cas simple comprenant trois points sur un réseau.\n\n\n\n\n\n\n::: {.cell}\n\n:::\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![Problèmes générés par la non-prise en compte du réseau : sous-estimation des distances](06-AnalyseReseauEvenements_files/figure-pdf/fig-illusAnalyseReseauA-1.pdf){#fig-illusAnalyseReseauA fig-align='center' width=85%}\n:::\n:::\n\n\n\n\n\n\nDeuxièmement, la non-prise en compte des lignes du réseau peut mener à analyser des secteurs dans lesquels les évènements ne peuvent pas se produire. La @fig-illusAnalyseReseauB illustre un cas où nous tenterions de produire un nouveau jeu de points distribués aléatoirement (points bleus), mais en respectant la densité initiale des points réels (points rouges). Ce type de méthode est notamment utilisé pour déterminer si un ensemble de points est plus ou moins concentré comparativement à ce que le hasard produirait. Comparer des points sur le réseau à des points hors du réseau conduit à surévaluer la concentration des points sur le réseau, car il y a plus d'espace en dehors du réseau que sur le réseau.\n\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![Problèmes générés par la non-prise en compte du réseau : surestimation de la concentration des points](06-AnalyseReseauEvenements_files/figure-pdf/fig-illusAnalyseReseauB-1.pdf){#fig-illusAnalyseReseauB fig-align='center' width=85%}\n:::\n:::\n\n\n\n\n\n\nTroisièmement, la masse des évènements ne se propage pas dans un espace en 2D comme dans un espace en 1,5D (@fig-illusAnalyseReseauC). Dans un réseau, la masse des évènements doit être divisée aux intersections. Si cette division n'est pas prise en compte, alors la masse des évènements est dupliquée aux intersections. Cette problématique se pose particulièrement aux méthodes d'estimation de densité par noyau que nous décrirons plus tard dans ce chapitre.\n\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![Problèmes générés par la non-prise en compte du réseau : la masse des évènements](06-AnalyseReseauEvenements_files/figure-pdf/fig-illusAnalyseReseauC-1.pdf){#fig-illusAnalyseReseauC fig-align='center' width=85%}\n:::\n:::\n\n\n\n\n\n\nDe nombreuses méthodes d'analyse de répartition ponctuelle ont été adaptées pour pouvoir être appliquées avec des réseaux géographiques [@okabe2012spatial]. Dans ce chapitre, nous abordons les méthodes de densité par noyau sur un réseau (*network kernel density estimation*, NKDE) et la création de matrices de pondération spatiale avec des distances sur un réseau pour calculer des mesures d'autocorrélation spatiale.\n\n## Cartographie de la densité d'évènements sur un réseau {#sec-062}\n\nÀ la [section @sec-0342], nous avons décrit les méthodes d'analyse de densité dans une maille régulière : carte de chaleur ou estimation de la densité par noyau (*kernel density estimation* -- KDE). Pour un rappel, une KDE peut être utilisée pour tenter de reconstruire un processus spatial produisant des évènements. Le processus spatial en lui-même est impossible à mesurer, mais nous tentons de le reconstruire et de l'approximer en nous basant sur les évènements observés qui sont des réalisations du processus sous-jacent. Sur un réseau, la logique est exactement la même : un processus spatial qui est invisible conduit à la réalisation d'évènements le long des lignes d'un réseau géographique.\n\n### Estimation de la densité des points sur un réseau {#sec-0621}\n\nL'estimation de la densité sur un réseau (*Network Kernel Density Estimation* -- NKDE) utilise une approche similaire à la KDE ([section @sec-0342]). L'idée générale est de répartir la masse des évènements le long des lignes du réseau autour de chaque évènement et d'additionner ensuite ces densités pour obtenir une estimation locale de l'intensité du processus spatial générant ces évènements. Comparativement à la KDE, les spécificités de la NKDE sont les suivantes :\n\n-   Les intensités sont calculées non pas sur des pixels, mais sur leurs équivalents appelés **lixels**. Un lixel correspond à simplement une portion de segment de ligne du réseau d'une longueur déterminée (50 mètres par exemple).\n\n-   Les distances sont calculées sur le réseau et non à vol d'oiseau.\n\nComme pour la KDE, il faut déterminer la valeur du rayon d'influence (*bandwidth*) et choisir une fonction *kernel*.\n\n#### Trois formes de NKDE {#sec-06211}\n\nLa NKDE peut prendre trois formes différentes traitant différemment la répartition de la masse aux intersections dans un réseau.\n\n\n\n\n\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n\n\n\n\n\n**NKDE géographique (Geo-NKDE)**. Il s'agit du cas le plus simple, car aucun traitement particulier n'est réalisé aux intersections du réseau et la densité d'un lixel est simplement basée sur la distance entre le centre de ce lixel et un évènement. Cette méthode est intuitive et peu coûteuse en temps de calcul, mais elle produit des résultats biaisés. En effet, si la masse d'un évènement se propage de façon continue dans toutes les directions à une intersection, alors la masse est multipliée par le nombre de directions possibles. Par exemple, à la @fig-GeoNKDEMasseBiais, qui comprend une intersection avec trois segments connectés, la masse totale est égale à 150 % et non à 100 %. Ainsi, dans un réseau avec de nombreuses intersections, l'intensité est systématiquement surestimée avec cette méthode.\n\n![Répartition de la masse avec une NKDE géographique](images/Chap06/GeoNKDEMasse.png){#fig-GeoNKDEMasseBiais width=\"50%\" fig-align=\"center\"}\n\nUn aperçu en 3D de la répartition de la masse est disponible à la figure ci-dessous avec un seul évènement.\n\n\n\n\n\n\n::: {.cell layout-align=\"center\" webgl='true'}\n::: {.cell-output-display}\n![Visualisation du Geo-NKDE](images/Chap06/image3D_a.jpg){#fig-GeoNKDE fig-align='center' width=100%}\n:::\n:::\n\n\n\n\n\n\nLa formule pour calculer la Geo-NKDE est :\n\n$$\n\\hat{\\lambda}_h(u)=\\frac{1}{h} \\sum_{i=1}^N k\\left(\\frac{\\operatorname{dist}_{\\text {net }}\\left(u, e_i\\right)}{h}\\right) \\text{ avec :}\n$$ {#eq-GeoNKDEeq}\n\n-   $\\hat{\\lambda}_h(u)$, l'estimation de l'intensité au point $u$ avec la *bandwidth* $h$.\n-   $N$, le nombre d'évènements.\n-   $k$, une fonction *kernel*.\n-   $\\operatorname{dist}_{\\text{net}}\\left(u, e_i\\right)$, la distance réseau entre la localisation $u$ et l'évènement $e_i$.\n\n**NKDE discontinue (ESD-NKDE)**. Cette seconde méthode impose que la masse des évènements soit divisée aux intersections par le nombre de directions possible. En procédant ainsi, il est possible d'éviter le biais de la Geo-NKDE, mais cela conduit à une estimation discontinue de la NKDE. En effet, l'intensité d'un évènement chute fortement au détour d'une intersection ce qui est contre-intuitif en géographie bien que l'intensité produite soit non biaisée (voir la figure ci-dessous). Comme pour la précédente, le second avantage de cette méthode est qu'elle est peu coûteuse en temps de calcul.\n\n\n\n\n\n\n::: {.cell layout-align=\"center\" webgl='true'}\n::: {.cell-output-display}\n![Visualisation du Geo-NKDE](images/Chap06/image3D_b.jpg){#fig-ESDNKDE fig-align='center' width=100%}\n:::\n:::\n\n\n\n\n\n\nLa formule pour calculer la ESD-NKDE est la suivante :\n\n$$\n\\hat{\\lambda}_h\\left(u, e_i\\right)=k\\left(d_{i s t_{n e t}}\\left(u, e_i\\right)\\right) \\prod_{j=1}^J\\left(\\frac{1}{\\left(n_{i j}-1\\right)}\\right) \\text{ avec :}\n$$ {#eq-ESDNKDEeq}\n\n-   $\\prod_{j=1}^J\\left(\\frac{1}{\\left(n_{i j}-1\\right)}\\right)$ est le terme qui permet de contrôler la réduction de la masse due aux $J$ intersections rencontrées entre $u$ et $e_i$ et ayant un nombre d'embranchements $n_{ij}$.\n\n**NKDE continue (ESC-NKDE)**. La troisième méthode implique également de diviser la masse des évènements aux intersections, mais aussi de corriger rétroactivement la masse précédant l'intersection pour forcer l'estimation à être continue. Cette estimation est donc non biaisée et ne produit pas de discontinuité (voir la figure ci-dessous). Cependant, la correction rétroactive nécessite un temps de calcul nettement plus long que les deux précédentes méthodes.\n\n\n\n\n\n\n::: {.cell layout-align=\"center\" webgl='true'}\n::: {.cell-output-display}\n![Visualisation du Geo-NKDE](images/Chap06/image3D_c.jpg){#fig-ESCNKDE fig-align='center' width=100%}\n:::\n:::\n\n\n\n\n\n\nDu fait de sa nature récursive, il est difficile de présenter la ESC-NKDE avec une équation. Cependant, l'algorithme complet est décrit par Atsuyuki Okabe et Sugihara Kokichi [-@okabe2012spatial].\n\nLa @fig-ComparaisonMasseNKDE permet de comparer la répartition de la masse des évènements aux intersections entre les NKDE, tandis que le @tbl-TabTroisNKDE résume les avantages et inconvénients des trois types de NKDE.\n\n![Comparaison des trois types de NDKDE : géographique (Geo-NKDE), discontinue (ESD-NKDE) et continue (ESC-NKDE)](images/Chap06/Comparaison3NKDE.jpg){#fig-ComparaisonMasseNKDE width=\"100%\" fig-align=\"center\"}\n\n\n\n\n\n\n::: {#tbl-TabTroisNKDE .cell tbl-cap='Comparaison des trois NKDE'}\n::: {.cell-output-display}\n\n\n|NKDE                         |Avantage                                        |Désavantage                               |\n|:----------------------------|:-----------------------------------------------|:-----------------------------------------|\n|NKDE géographique (Geo-NKDE) |Intuitive et facile à calculer                  |La somme de la masse totale est inexacte. |\n|NKDE discontinue (ESD-NKDE)  |Respect de la masse totale et facile à calculer |L’espace discontinu est contre-intuitif   |\n|NKDE continue (ESC-NKDE)     |Respect de la masse totale et intuitive         |Couteux en termes de temps de calcul      |\n\n\n:::\n:::\n\n\n\n\n\n\n::: bloc_aller_loin\n::: bloc_aller_loin-header\n::: bloc_aller_loin-icon\n:::\n\n***Package*** **`spNetwork`**\n:::\n\n::: bloc_aller_loin-body\nPour une lecture plus détaillée sur les trois NKDE, nous vous recommandons de lire l'article décrivant le *package* `spNetwork` [@RJ-2021-102].\n:::\n:::\n\n#### Correction de Diggle {#sec-06212}\n\nTrès souvent, les données collectées pour un phénomène analysé sont limitées à une zone géographique (territoire d'étude) et les évènements se produisant en dehors de cette zone ne sont pas enregistrés. Ce biais de collecte entraîne une sous-estimation systématique de l'intensité estimée par les méthodes KDE et NKDE aux frontières de la zone d'étude. Pour limiter cette sous-estimation, il est préférable de collecter directement les données dans un périmètre plus large que la zone étudiée. Cependant, lorsque les données ont déjà été collectées, il est possible d'appliquer la correction de Diggle [-@diggle1985kernel] (@eq-DigglesCor).\n\n$$\n\\begin{gathered}\n\\lambda^D(u)=\\frac{1}{bw} \\sum_{i=1}^n w_i \\cdot \\frac{1}{e\\left(e_i\\right)} K\\left(\\operatorname{dist}\\left(u, e_i\\right)\\right) \\\\\ne(u)=\\int_W^v K(\\operatorname{dist}(u, v)) \\text{ avec :}\n\\end{gathered}\n$$ {#eq-DigglesCor}\n\n-   $e(u)$ étant la masse de l'évènement $u$ localisé dans la zone d'étude $W$.\n\nConcrètement, cette correction propose d'augmenter la masse des évènements localisés à proximité de la frontière de la zone d'étude. Ces évènements voient leur pondération multipliée par l'inverse de la proportion de leur masse comprise à l'intérieur de la zone d'étude. Ainsi, un point dont 100 % de la masse se trouve dans la zone d'étude garde le même poids (1/1 = 1); un point avec 75 % de sa masse dans la zone d'étude a son poids multiplié par 4/3 (1/0,75 = 4/3) et un point avec 50 % de sa masse dans la zone d'étude a son poids multiplié par deux (1/0,5 = 2).\n\n#### *Bandwidths* adaptatives {#sec-06213}\n\nJusqu'ici, nous avons présenté les méthodes d'estimation de la densité par *kernel* avec des *bandwidths* globales. Il existe une catégorie de *kernels* appelés adaptatifs qui utilisent, comme leur nom l'indique, des *bandwidths* s'adaptant localement.\n\nL'idée générale est que chaque évènement peut avoir sa propre *bandwidth* locale. Cette modification se justifie du point de vue théorique. Pour un rappel, nous considérons que les évènements ont eu lieu à un certain endroit du fait d'un patron spatial d'arrière-plan. Nous formulons donc l'hypothèse qu'un évènement aurait pu se produire dans un certain rayon (*bandwidth*) autour de son emplacement réel selon une probabilité décroissante avec la distance (fonction *kernel*). Dans les secteurs où se situent de nombreux points, notre incertitude sur la localisation d'un point est moins grande, nous pouvons donc utiliser des *bandwidths* plus petites. Cependant, dans les secteurs avec très peu de points, le processus spatial est beaucoup plus diffus et l'évènement aurait pu se produire dans un rayon plus large, incitant à utiliser des *bandwidths* plus grandes.\n\nDeux approches sont le plus souvent utilisées pour créer des *bandwidths* locales : la méthode d'Abramson [-@abramson1982bandwidth] et la méthode des *k* plus proches voisins [@orava2011k].\n\n##### *Bandwidths* adaptatives par la méthode d'Abramson {#sec-062131}\n\nLa méthode d'Abramson [-@abramson1982bandwidth] propose d'utiliser des *bandwidths* locales qui sont inversement proportionnelles à la racine carrée de l'intensité locale du processus spatial étudié. Cependant, puisque nous ne disposons pas d'une mesure de ce processus, nous devons en fournir une approximation à priori. Cette approximation est obtenue en sélectionnant une première *bandwidth* globale (appelée pilote) et l'estimation de la densité est effectuée. Une fois que la densité à priori est calculée à la localisation exacte de chaque évènement, il est ensuite possible de calculer une *bandwidth* locale pour chaque évènement avec l'@eq-AbramsonBW :\n\n$$\nh(e_{i}) = h_{0} \\times \\frac{1}{\\sqrt{\\tilde{f}h_{0}(e_{i})}} \\times \\frac{1}{\\gamma_{f}}\\\\\n\\gamma_{f} = \\exp(\\frac{\\sum_{i}log(\\frac{1}{\\sqrt{\\tilde{f}h_{0}(e_{i})}})}{n}) \\text{ avec :}\n$$ {#eq-AbramsonBW}\n\n-   $h(e_{i})$ est la *bandwidth* locale pour l'évènement $e_{i}$.\n-   $h_0$ est la *bandwidth* pilote globale.\n-   $\\tilde{f}h_{0}(e_{i})$ est l'estimation locale de la densité à priori pour l'évènement $e_{i}$ avec $h_0$.\n\nL'objectif est bien évidemment de sélectionner la *bandwidth* pilote $h_0$.\n\n##### *Bandwidths* adaptatives par la méthode des *k* plus proches voisins {#sec-062132}\n\nCette méthode est certainement plus facile à expliquer. Elle consiste à calculer, pour chaque évènement, la distance qui le sépare de son plus proche voisin de rang *k* (*k* étant un entier plus grand que 0). Dans des secteurs avec peu d'évènements, la distance au plus proche voisin de rang *k* sera plus grande. L'enjeu pour cette méthode est donc de déterminer *k*. La @fig-ESCNKDE2 illustre l'impact de ces méthodes sur les *bandwidths* locales en prenant le jeu de données fourni dans le *package* `spNetwork`, portant sur les accidents à vélo dans les quartiers centraux de Montréal.\n\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![Comparaison des deux principales méthodes de création de *bandwidths* locales](06-AnalyseReseauEvenements_files/figure-pdf/fig-ESCNKDE2-1.pdf){#fig-ESCNKDE2 fig-align='center' width=100%}\n:::\n:::\n\n\n\n\n\n\n#### Sélection d'une *bandwidth* {#sec-06214}\n\nComme signalé dans la [section @sec-03421], le choix de la *bandwidth* est crucial dans l'application d'une estimation de densité par *kernel*. Dans le cas de la NKDE, le nombre de méthodes est plus limité que pour la KDE, mais il est toujours possible d'utiliser l'approche par validation croisée des probabilités (*likelihood cross validation*). Plus exactement, cette méthode choisit une *bandwidth* de façon à minimiser l'impact qu'aurait le fait de retirer un évènement du jeu de donnée (*leave one out cross validation*). En effet, puisque chaque point est une réalisation d'un processus spatial, le fait de retirer un point des données ne devrait affecter que marginalement l'estimation locale de l'intensité du processus spatial. Il est possible de minimiser ce score en sélectionnant la bonne *bandwidth*. Il est possible de calculer ce score pour une *bandwidth* donnée avec l'@eq-LOOLCV :\n\n$$\n\\operatorname{LCV}(bw)=\\sum_i \\log \\hat{\\lambda}_{-i}\\left(x_i\\right)\n \\text{ avec :}\n$$ {#eq-LOOLCV}\n\n-   $bw$ est la *bandwidth* à évaluer.\n-   $\\hat{\\lambda}_{-i}$ est l'intensité estimée à la localisation de l'évènement *i* sans la présence de l'évènement *i*.\n\nNotez qu'il s'agit d'une simplification de l'équation qui comporte normalement un second terme qui tend à être une constante et peut donc être retiré pour alléger les calculs [@loader2006local]. Cette méthode peut aussi être utilisée pour sélectionner la *bandwidth* pilote ou *k* lorsque nous utilisons une *bandwidth* adaptative.\n\n### Mise en œuvre dans R {#sec-0612}\n\nNous analysons ici les collisions ayant eu lieu sur le réseau routier de la ville de Sherbrooke. Nous commençons par appliquer une NKDE avec *bandwidth* fixe et nous la comparons avec deux NKDE utilisant des *bandwidths* adaptatives. Nous utilisons principalement le *package* `spNetwork` [@RJ-2021-102].\n\nLa première étape consiste à charger les données des accidents et le réseau routier. La @fig-situationNKDE permet de visualiser la répartition spatiale des accidents.\n\n\n\n\n\n\n::: {.cell}\n\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(sf)\nlibrary(tmap)\nlibrary(ggplot2)\nlibrary(spNetwork)\nlibrary(future) # package utilisé pour accélérer les calculs dans spNetwork\nfuture::plan(future::multisession(workers = 5))\n## Importation des couches géographiques\nroutes <- st_read('data/chap01/shp/Segments_de_rue.shp', quiet = TRUE)\ncollisions <- st_read('data/chap04/DataAccidentsSherb.shp', quiet = TRUE)\n## Application de la même projection\nroutes <- st_transform(routes, 2949)\nroutes <- sf::st_cast(routes, 'LINESTRING')\ncollisions <- st_transform(collisions, 2949)\n## Cartographie des données des collisions et du réseau routier\ntm_shape(routes) + \n  tm_lines('grey20') + \n  tm_shape(collisions) + \n  tm_dots('red', size = 0.05)+\ntm_layout(frame = FALSE)  \n```\n\n::: {.cell-output-display}\n![Accidents sur le réseau routier de la ville de Sherbrooke](06-AnalyseReseauEvenements_files/figure-pdf/fig-situationNKDE-1.pdf){#fig-situationNKDE fig-align='center' fig-pos='H' width=85%}\n:::\n:::\n\n\n\n\n\n\nPour l'analyse, nous utilisons la fonction *kernel* quadratique et la NKDE continue (ESC-NKDE). Puis, nous choisissons une *bandwidth* avec l'approche par validation croisée des probabilités. Notez que pour réduire le temps de calcul, la NKDE discontinue (ESD-NKDE) est utilisée dans la phase de sélection de la *bandwidth*, car il est bien plus rapide à calculer.\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\neval_bandwidth <- bw_cv_likelihood_calc.mc(\n  bws = seq(100, 1200, 50),\n  lines = routes, \n  events = collisions,\n  w = rep(1, nrow(collisions)), # le poids de chaque évènement est 1\n  kernel_name = 'quartic',\n  method = 'discontinuous',\n  adaptive = FALSE,\n  max_depth = 10,\n  digits = 1,\n  tol = 0.1,\n  agg = 5, # les accidents dans un rayon de 5 mètres seront agrégés\n  grid_shape = c(5,5),\n  verbose = TRUE)\n```\n:::\n\n\n\n\n\n\nÀ la @fig-bwScoresNKDE, nous constatons qu'au-delà de 900 mètres, le gain obtenu en augmentant la valeur de la *bandwidth* est marginal. Par conséquent, nous retenons cette valeur de *bandwidth* pour la première estimation de l'intensité des accidents.\n\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n## Graphique pour les bandwidths \nggplot(eval_bandwidth) + \n  geom_path(aes(x = bw, y = cv_scores)) + \n  geom_point(aes(x = bw, y = cv_scores), color = 'red')+\n  labs(x = \"Valeur de la bandwidth\", y = \"Valeur du CV\")\n```\n\n::: {.cell-output-display}\n![Scores des *bandwidths* globales](06-AnalyseReseauEvenements_files/figure-pdf/fig-bwScoresNKDE-1.pdf){#fig-bwScoresNKDE fig-align='center' fig-pos='H' width=75%}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n## Création des lixels d'une longueur de 100 mètres\nlixels <- lixelize_lines(routes, 100, mindist = 50)\n## Centroïdes des lixels\nlixels_centers <- spNetwork::lines_center(lixels)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n## Calcul de la NKDE\nfuture::plan(future::multisession(workers=2))\nintensity <- nkde.mc(lines = routes,\n                     events = collisions,\n                     w = rep(1, nrow(collisions)),\n                     samples = lixels_centers,\n                     kernel_name = 'quartic',\n                     bw = 900,\n                     adaptive = FALSE,\n                     method = 'continuous',\n                     max_depth = 8,\n                     digits = 1,\n                     tol = 0.1,\n                     agg = 5,\n                     verbose = FALSE,\n                     grid_shape = c(5,5))\nif (!inherits(future::plan(), \"sequential\")) future::plan(future::sequential)\n```\n:::\n\n\n\n\n\n\nUne fois que les valeurs de densité sont obtenues, nous pouvons les cartographier à l'échelle des lixels (@fig-mapNKDE).\n\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlixels$density <- intensity * 1000\ntm_shape(lixels) + \n  tm_lines(\"density\", lwd = 1.5, n = 7, style = \"fisher\",\n           legend.format = list(text.separator = \"à\"))+\n  tm_layout(frame=FALSE)\n```\n\n::: {.cell-output-display}\n![Densité des accidents sur le réseau routier de Sherbrooke](06-AnalyseReseauEvenements_files/figure-pdf/fig-mapNKDE-1.pdf){#fig-mapNKDE fig-align='center' fig-pos='H' width=100%}\n:::\n:::\n\n\n\n\n\n\nNous pouvons à présent utiliser une *bandwidth* adaptative. Pour cela, nous devons réévaluer les différentes *bandwidths* globales avec l'approche par validation croisée des probabilités.\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfuture::plan(future::multisession(workers=2))\neval_bandwidth_adapt <- bw_cv_likelihood_calc.mc(\n  bws = seq(100, 1200, 50),\n  lines = routes, \n  events = collisions,\n  w = rep(1, nrow(collisions)), # le poids de chaque évènement sera 1\n  kernel_name = 'quartic',\n  method = 'discontinuous',\n  adaptive = TRUE,\n  trim_bws = seq(100, 1200, 50) * 2,\n  max_depth = 10,\n  digits = 2,\n  tol = 0.1,\n  agg = 5, # tous les accidents dans un rayon de 5m seront agrégés\n  grid_shape = c(5,5),\n  verbose = TRUE\n)\nif (!inherits(future::plan(), \"sequential\")) future::plan(future::sequential)\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nggplot() + \n  geom_path(data = eval_bandwidth,\n            mapping =  aes(x = bw, y = cv_scores)) + \n  geom_point(data = eval_bandwidth,\n             mapping =  aes(x = bw, y = cv_scores), color = 'red') + \n  geom_path(data = eval_bandwidth_adapt,\n            mapping =  aes(x = bw, y = cv_scores)) + \n  geom_point(data = eval_bandwidth_adapt,\n             mapping =  aes(x = bw, y = cv_scores), color = 'blue')+\n  labs(x = \"Valeur de la bandwidth\", y = \"Valeur du CV\")\n```\n\n::: {.cell-output-display}\n![Scores des bandwidths adaptatives](06-AnalyseReseauEvenements_files/figure-pdf/fig-bwScoresNKDEadpt-1.pdf){#fig-bwScoresNKDEadpt fig-align='center' fig-pos='H' width=65%}\n:::\n:::\n\n\n\n\n\n\nLa @fig-bwScoresNKDEadpt indique que les scores obtenus par les *bandwidths* adaptatives sont systématiquement supérieurs à ceux obtenus par les *bandwidths* fixes. Nous gardons une *bandwidth* pilote de 900 mètres pour recalculer notre ESC-NKDE avec une *bandwidth* adaptative.\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nintensity_adpt <- nkde.mc(lines = routes,\n                  events = collisions,\n                  w = rep(1, nrow(collisions)),\n                  samples = lixels_centers,\n                  kernel_name = 'quartic',\n                  bw = 900,\n                  adaptive = TRUE,\n                  trim_bw = 1800,\n                  method = 'continuous',\n                  max_depth = 8,\n                  digits = 1,\n                  tol = 0.1,\n                  agg = 5,\n                  verbose = TRUE,\n                  grid_shape = c(5,5))\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlixels$density_adpt <- intensity_adpt$k * 1000\ntm_shape(lixels) + \n  tm_lines(\"density_adpt\", lwd = 1.5, n = 7, style = \"fisher\",\n           legend.format = list(text.separator = \"à\"))+\n  tm_layout(frame=FALSE)\n```\n\n::: {.cell-output-display}\n![Densité des accidents sur le réseau routier de Sherbrooke avec une *bandwidth* adaptative](06-AnalyseReseauEvenements_files/figure-pdf/fig-mapNKDEadpt-1.pdf){#fig-mapNKDEadpt fig-align='center' fig-pos='H' width=100%}\n:::\n:::\n\n\n\n\n\n\nComparativement aux résultats obtenus avec les *bandwidths* fixes, nous constatons que le lissage est beaucoup plus faible et que les points chauds sont plus faciles à identifier. Le *package* `spNetwork` permet aussi d'utiliser la méthode des *k* plus proches voisins comme *bandwidth* locale.\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nknn_net <- spNetwork::network_knn(collisions,\n                                      lines = routes,\n                                      k = 30,\n                                      maxdistance = 3000,\n                                      grid_shape = c(1,1),\n                                      verbose = FALSE)\ndist_mat <- knn_net$distances\n# Nous limitons les bandwidths avec des bornes de 100 à 3000 m\ndist_mat <- ifelse(dist_mat > 3000, 3000, dist_mat)\ndist_mat <- ifelse(dist_mat < 100, 100, dist_mat)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\neval_bandwidth_knearest <- bw_cv_likelihood_calc(\n  bws = NULL,\n  mat_bws = dist_mat, \n  lines = routes, \n  events = collisions,\n  w = rep(1, nrow(collisions)), # le poids de chaque évènement sera 1\n  kernel_name = 'quartic',\n  method = 'discontinuous',\n  adaptive = TRUE,\n  trim_bws = NULL,\n  max_depth = 10,\n  digits = 1,\n  tol = 0.1,\n  agg = 5, # tous les accidents dans un rayon de 5 mètres seront agrégés\n  grid_shape = c(5,5),\n  verbose = TRUE\n)\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\neval_bandwidth_knearest$knn <- 1:30\nggplot() + \n  geom_path(data = eval_bandwidth_knearest,\n            mapping =  aes(x = knn, y = cv_scores)) + \n  geom_point(data = eval_bandwidth_knearest,\n             mapping =  aes(x = knn, y = cv_scores), color = 'red')+\n  labs(x = \"Nombre de plus proches voisins (k)\", y = \"Valeur du CV\")\n```\n\n::: {.cell-output-display}\n![Scores des bandwidths adaptatives par *k* plus proches voisins](06-AnalyseReseauEvenements_files/figure-pdf/fig-bwSscoresNKDEK-1.pdf){#fig-bwSscoresNKDEK fig-align='center' fig-pos='H' width=65%}\n:::\n:::\n\n\n\n\n\n\nLa @fig-bwSscoresNKDEK indique que le meilleur score est obtenu pour une *bandwidth* allant jusqu'au 16^e^ voisin.\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nintensity_adpt_knn <- nkde.mc(lines = routes,\n                  events = collisions,\n                  w = rep(1, nrow(collisions)),\n                  samples = lixels_centers,\n                  kernel_name = 'quartic',\n                  bw = dist_mat[,16],\n                  trim_bw = 1800,\n                  method = 'continuous',\n                  max_depth = 8,\n                  digits = 1,\n                  tol = 0.1,\n                  agg = 5,\n                  verbose = TRUE,\n                  grid_shape = c(5,5))\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlixels$density_adpt_knn <- intensity_adpt_knn * 1000\ntm_shape(lixels) + \n  tm_lines(\"density_adpt_knn\", lwd = 1.5, n = 7, style = \"fisher\",\n           legend.format = list(text.separator = \"à\"))+\n  tm_layout(frame=FALSE)\n```\n\n::: {.cell-output-display}\n![Densité des accidents sur le réseau routier de Sherbrooke avec une *bandwidth* adaptative pour 16 plus proches voisins](06-AnalyseReseauEvenements_files/figure-pdf/fig-mapNKDEknn-1.pdf){#fig-mapNKDEknn fig-align='center' fig-pos='H' width=100%}\n:::\n:::\n\n\n\n\n\n\n### Estimation de la densité spatio-temporelle sur un réseau {#sec-0623}\n\nComme nous avons pu le voir dans la [section @sec-0343], il est courant d'analyser des données d'évènements disposant à la fois d'une localisation dans l'espace et dans le temps. Il est alors possible de calculer une densité spatio-temporelle, soit de lisser les évènements à la fois dans la dimension spatiale et dans la dimension temporelle. Plus exactement, la densité d'un évènement *i* en un point *p* et un instant *t* correspond au produit de la densité spatiale et de la densité temporelle de *i*.\n\nCette extension est aussi valide dans le cas de l'analyse d'évènement sur réseau.\n\n$$\n\\hat{\\lambda}_{h_n h_t}\\left(u_{n t}\\right)=\\frac{1}{h_n h_t} \\sum_{i=1}^N k_{n e t}\\left(\\frac{\\operatorname{dist}_{n e t}\\left(u_{n t}, e_i\\right)}{h_n}\\right) \\sum_{i=1}^N k_{\\text {time }}\\left(\\frac{\\operatorname{dist}_{\\text {time }}\\left(u_{n t}, e_i\\right)}{h_t}\\right)\n\\text{ avec :}\n$$\n\n-   $h_t$ et $h_n$ les *bandwidths* temporelle et réseau.\n-   $u_{nt}$ un évènement localisé au point *n* du réseau et à l'instant *t* dans le temps.\n\nLa @fig-TNKDEvis illustre le calcul de la TNKDE, soit l'estimation de la densité spatio-temporelle sur un réseau (*Temporal Network Kernel Density Estimate*).\n\n![La TNKDE comme produit des densités spatiale et temporelle](images/Chap06/TNKDE_produit.jpg){#fig-TNKDEvis width=\"85%\" fig-align=\"center\"}\n\nComme pour le NKDE, il est possible de :\n\n-   Utiliser des *bandwidths* variant localement dans l'espace et le temps.\n\n-   Comparer des *bandwidths* par des méthodes de validation croisée.\n\n-   Appliquer des correctifs aux frontières spatio-temporelles de la zone d'étude.\n\n#### Application dans R {#sec-06231}\n\nNous reprenons simplement l'exemple de la section sur la NKDE et voir comment l'étendre au contexte spatio-temporel. Pour cela, nous utiliserons principalement le *package* `spNetwork`.\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(sf)\nlibrary(spNetwork)\nlibrary(lubridate)\nlibrary(metR)\nlibrary(future) # pour accélérer les calculs de spNetwork\nfuture::plan(future::multisession(workers = 5))\n\nroutes <- st_read('data/chap01/shp/Segments_de_rue.shp', quiet = TRUE)\ncollisions <- st_read('data/chap04/DataAccidentsSherb.shp', quiet = TRUE)\n## Préparation de la colonne avec les dates\ncollisions$dt <- as_date(collisions$DATEINCIDE)\ncollisions$dt_num <- as.numeric(collisions$dt - min(collisions$dt))\n## Reprojection dans le même système\nroutes <- st_transform(routes, 32187)\ncollisions <- st_transform(collisions, 32187)\nroutes <- sf::st_cast(routes, 'LINESTRING')\nroutes$length <- st_length(routes)\n## Préparation des routes et des lixels\nroutes <- sf::st_cast(routes, 'LINESTRING')\n```\n:::\n\n::: {.cell}\n\n:::\n\n\n\n\n\n\nNous commençons par compléter le réseau routier. En effet, certaines sections sont isolées et forment des enclaves inaccessibles. Nous avons ignoré cette problématique jusqu'ici, mais nous verrons comment retirer les petites enclaves déconnectées de la partie principale du réseau. Pour cela, nous commençons par créer un objet de type `graph` à partir des routes avec le *package* `spNetwork`.\n\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(igraph)\nlibrary(dbscan)\nlibrary(tmap)\nroutes <- sf::st_cast(routes, 'LINESTRING')\nroutes$length <- st_length(routes)\ngraph <- spNetwork::build_graph(routes, digits = 2,line_weight = \"length\")\nparts <- components(graph$graph)\ngraph$spvertices$part <- as.character(parts$membership)\ntm_shape(graph$spvertices) + \n  tm_dots(\"part\", size = 0.1)\n```\n\n::: {.cell-output-display}\n![Visualisation des composantes du réseau routier](06-AnalyseReseauEvenements_files/figure-pdf/fig-networkComponents-1.pdf){#fig-networkComponents fig-align='center' fig-pos='H' width=85%}\n:::\n:::\n\n\n\n\n\n\nÀ la @fig-networkComponents, nous pouvons identifier la partie principale du réseau et les segments déconnectés (éléments avec des valeurs supérieures à 1). Puis, nous soustrayons ces éléments du réseau pour alléger le graphe et éviter d'associer des collisions avec des parties inaccessibles du réseau routier.\n\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nmain_component <- subset(graph$spvertices, graph$spvertices$part == \"1\")\nmain_network <- subset(graph$spedges, \n                   (graph$spedges$start_oid %in% main_component$id) | \n                   (graph$spedges$end_oid %in% main_component$id)\n                   )\nmain_network <- subset(main_network, as.numeric(st_length(main_network)) > 0)\n```\n:::\n\n\n\n\n\n\nMaintenant que nous avons nettoyé notre réseau, nous calculons les scores pour les *bandwidths*.\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlixels_main <- lixelize_lines(main_network, 100, mindist = 50)\nlixels_main_centers <- spNetwork::lines_center(lixels_main)\n# Calcul des scores pour les bandwidths\ncv_scores_tnkde <- bw_tnkde_cv_likelihood_calc(\n  bws_net = seq(700, 1500, 100),\n  bws_time =  seq(10, 40, 5),\n  lines = main_network,\n  events = collisions,\n  time_field = \"dt_num\",\n  w = rep(1, nrow(collisions)),\n  kernel_name = \"quartic\",\n  method = \"continuous\",\n  max_depth = 10,\n  digits = 2,\n  tol = 0.1,\n  agg = 10,\n  grid_shape = c(5,5),\n  verbose = TRUE)\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Création d'un graphique pour visualiser les résultats\nlibrary(ggplot2)\ndf2 <- reshape2::melt(cv_scores_tnkde)\nggplot(df2) + \n  geom_tile(aes(x = Var1, y = Var2, fill = value)) + \n  geom_contour(aes(x = Var1, y = Var2, z = value),\n               breaks = c(-400,-300, -250, -200, -180, -150),\n               color = 'white', linetype = 'dashed')+\n  scale_fill_viridis_c() + \n  labs(x = \"Bandwidth spatiale (mètres)\", \n       y = \"Bandwidth temporelle (jours)\", \n       fill = \"cv score\") +\n  coord_fixed(ratio=30)\n```\n\n::: {.cell-output-display}\n![Scores obtenus pour différentes combinaisons de *bandwidths* spatiales et temporelles](06-AnalyseReseauEvenements_files/figure-pdf/fig-scorestnkde-1.pdf){#fig-scorestnkde fig-align='center' fig-pos='H' width=85%}\n:::\n:::\n\n\n\n\n\n\nLa @fig-scorestnkde indique clairement que des *bandwidths* plus larges produisent de meilleurs résultats. Pour éviter d'avoir des résultats trop lissées, nous choisisons dans un premier temps la paire de *bandwidths* 30 jours et 1500 m. Puisque le temps de calcul peut être assez long compte tenu de la longueur des *bandwidths* (supérieure à 1 km), nous continuons donc à utiliser une NKDE discontinue.\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Choix de la résolution temporelle (dix jours ici)\nsample_time <- seq(0, max(collisions$dt_num), 10)\n# Calcul des densités\ntnkde_densities <- tnkde.mc(lines = main_network,\n                   events = collisions,\n                   time_field = \"dt_num\",\n                   w = rep(1, nrow(collisions)), \n                   samples_loc = lixels_main_centers,\n                   samples_time = sample_time, \n                   kernel_name = \"quartic\",\n                   bw_net = 1500, bw_time = 30,\n                   adaptive = TRUE,\n                   trim_bw_net = 1800,\n                   trim_bw_time = 60,\n                   method = \"continuous\",\n                   div = \"bw\", max_depth = 10,\n                   digits = 2, tol = 0.01,\n                   adaptive_separate = FALSE,\n                   agg = 10, grid_shape = c(5,5), \n                   verbose  = TRUE)\n```\n:::\n\n\n\n\n\n\nOn peut à présent représenter notre TNKDE avec une carte animée!\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(classInt)\nlibrary(viridis)\nall_times <- min(collisions$dt) + days(sample_time)\ntnkde_densities$k <- tnkde_densities$k*10000\ntnkde_densities$k <- ifelse(tnkde_densities$k < 0, 0, tnkde_densities$k)\ncolor_breaks <- classIntervals(c(tnkde_densities$k), n = 10, style = \"kmeans\")\nall_maps <- lapply(1:length(all_times), function(i){\n  dens <- tnkde_densities$k[,i]\n  dt <- all_times[[i]]\n  lixels_main$dens <- dens\n  lixels2 <- lixels_main[order(-1*lixels_main$dens),]\n  map <- tm_shape(lixels2) + \n    tm_lines(\"dens\", breaks = color_breaks$brks,\n             palette = mako(10,direction = -1), lwd = 2) + \n    tm_layout(frame = FALSE, legend.show=FALSE,\n              main.title = as.character(all_times[[i]]))\n  return(map)\n})\n# Création d'une animation pour produire la carte animée\ntmap_animation(all_maps, filename = \"images/Chap06/animated_TNKDE_sherbrooke.gif\", \n               width = 1000, height = 1000, dpi = 150, delay = 50)\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![Densité spatio-temporelle des collisions routières à Sherbrooke](images/Chap06/animated_TNKDE_sherbrooke.jpg){#fig-animated_tnkde fig-align='center' width=85%}\n:::\n:::\n\n\n\n\n\n\n\n## Mesure d'autocorrélation spatiale sur un réseau {#sec-063}\n\nDans le [chapitre @sec-chap03], nous avons présenté plusieurs mesures d'autocorrélation spatiale globales et locales. À titre de rappel, ces mesures utilisent une matrice $W$ indiquant les relations spatiales (voisinage, distance, interaction) entre les observations. Lorsque nous analysons des observations sur un réseau, l'utilisation de matrices spatiales basées sur les distances réseaux plutôt qu'euclidiennes permet de représenter plus fidèlement l'organisation spatiale des observations. Voici quelques exemples de matrices de pondération spatiale construites à partir de distances calculées sur un réseau :\n\n-   Matrice de connectivité selon la distance ([section @sec-02222]) : deux observations sont considérées comme voisines si la longueur du plus court chemin qui les sépare est inférieure au seuil de distance maximal fixé.\n\n-   Matrice des *k* plus proches voisins ([section @sec-02224]) : une observation a uniquement pour voisins les *k* autres observations les plus proches.\n\n-   Matrices basées sur la distance ([section @sec-02223]) : chaque observation est voisine de toutes les autres observations et le poids accordé à une paire d'observations dans la matrice est obtenu en appliquant une fonction décroissante (inverse de la distance, inverse de la distance au carrée, inverse de l'exponentielle, etc.) à la longueur du plus court chemin entre les deux observations. Si la fonction renvoie une pondération de 0, alors les deux observations sont trop éloignées pour être considérées comme voisines.\n\nCes matrices peuvent ensuite être standardisées en ligne tel que décrit dans la [section @sec-0223].\n\nUn bon exemple d'utilisation de ce type de matrice est l'évaluation de l'autocorrélation spatiale de l'intensité estimée par la méthode NKDE vu dans la [section @sec-061]. En effet, la NKDE est une méthode essentiellement descriptive. Par conséquent, appliquer une mesure classique d'autocorrélation spatiale locale, comme les statistiques locales de Getis et Ord ([section @sec-0241]) ou la typologie basée sur le diagramme de Moran dans un contexte univarié ([section @sec-02431]), permet d'identifier les points chauds et froids de densité d'événemements statistiquement significatifs. Cette approche a notamment été proposée par Ikuho Yamada et Jean-Claude Thill [-@yamada2007local] sous le nom de *ILINCS* (*I Local Indicators of Network-Constrained Clusters*), mais ces auteurs utilisaient à l'époque une GEO-NKDE. Nous reprenons donc l'exemple précédent avec l'ESC-NKDE estimée pour les collisions routières à Sherbrooke et calculons le *I* de Moran global et une mesure d'autocorrélation spatiale locale sur les lixels, soit la typologie basée sur le diagramme de Moran.\n\n### Mise en œuvre dans R {#sec-0631}\n\nLa première étape consiste à créer une matrice de pondération spatiale entre les lixels sur le réseau routier de Sherbrooke. Nous testons plusieurs matrices pour trouver celle qui permet d'obtenir la plus haute valeur pour le *I* de Moran global.\n\nPour commencer, nous calculons simplement les distances réseau entre les lixels à l'aide de `spNetwork`. Notez que la fonction `network_listw` et sa version multicœur `network_listw.mc` renvoient un objet de type `listw` typique du *package* `spdep`. Il est aussi possible de l'utiliser pour simplement obtenir des distances (avec les paramètres `dist_func = 'identity'` et `matrice_type = 'I'`) pour ensuite leur appliquer des fonctions spécifiques. Nous utilisons ici cette approche pour éviter d'avoir à calculer plusieurs fois les chemins plus courts entre les lixels. Pour réduire le temps de calcul de la matrice, nous fixons la distance maximale à 2500 mètres avec (paramètre `maxdistance = 2500` de la fonction `spNetwork::network_listw.mc`).\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nroutes <- st_read('data/chap01/shp/Segments_de_rue.shp', quiet = TRUE)\nroutes <- st_transform(routes, 2949)\nroutes <- sf::st_cast(routes, 'LINESTRING')\nfuture::plan(future::multisession(workers = 5))\nnet_distances <- spNetwork::network_listw.mc(\n  origins = lixels_centers, \n  lines = routes,\n  maxdistance = 2500,\n  mindist = 1,\n  dist_func = 'identity',\n  matrice_type = 'I',\n  grid_shape = c(5, 5)\n)\n```\n:::\n\n\n\n\n\n\nPremièrement, nous construisons plusieurs matrices de connectivité selon la distance standardisées en ligne, captant les voisins à moins de 250, 300, 500, 700 et 900 mètres (rappelons que les lixels ont une longueur de 100 m et que nous partons du centre des lixels pour le calcul des distances).\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# une liste qui permettra de stocker toutes les matrices\nall_matrices <- list()\nbin_dists <- c(250, 300, 500, 700, 900)\nfor(d in bin_dists){\n  new_weights <- lapply(net_distances$weights, function(x){\n    return( (x <= d) / sum(x <= d))\n  })\n  net_distances_temp <- net_distances\n  net_distances_temp$weights <- new_weights\n  all_matrices[[paste0(\"dist_mat_\",d)]] <- net_distances_temp\n}\n```\n:::\n\n\n\n\n\n\nDeuxièmement, nous considérons un ensemble de matrices binaires standardisées en ligne captant les *k* plus proches voisins (de 3 à 10); il faut cependant que les distances entre les observations restent inférieures à 2500 mètres.\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfor(k in 3:10){\n  new_weights <- lapply(net_distances$weights, function(x){\n    x_r <- rank(x, ties.method = \"min\")\n    return( (x_r <= k) / sum(x_r <= k))\n  })\n  net_distances_temp <- net_distances\n  net_distances_temp$weights <- new_weights\n  all_matrices[[paste0(\"k_mat_\",k)]] <- net_distances_temp\n}\n```\n:::\n\n\n\n\n\n\nTroisièmement, nous construisons des matrices avec l'inverse de la distance, l'inverse de la distance au carrée et un *kernel* quadratique avec des seuils maximaux de la distance fixés à 250, 300, 500, 700 et 900 mètres.\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Inverse de la distance\ninv_weights <- lapply(net_distances$weights, function(x){\n  inv <- (1/x) \n  return(inv / sum(inv))\n})\nnet_distances_temp <- net_distances\nnet_distances_temp$weights <- inv_weights\nall_matrices[[\"inv_mat\"]] <- net_distances_temp\n\ninv2_weights <- lapply(net_distances$weights, function(x){\n  inv <- (1/x**2) \n  return(inv / sum(inv))\n})\n\n# Inverse de la distance au carré\nnet_distances_temp <- net_distances\nnet_distances_temp$weights <- inv2_weights\nall_matrices[[\"inv2_mat\"]] <- net_distances_temp\n\nbin_dists <- c(250, 300, 500, 700, 900)\n\nfor(d in bin_dists){\n  new_weights <- lapply(net_distances$weights, function(x){\n    if(is.null(x) == FALSE){\n      w <- spNetwork::quartic_kernel(x,d)\n      return( (w) / sum(w))\n    }\n    else{\n      return(NULL)\n    }\n  })\nnet_distances_temp <- net_distances\nnet_distances_temp$weights <- new_weights\nall_matrices[[paste0(\"dist_quartic_\",d)]] <- net_distances_temp\n}\n```\n:::\n\n\n\n\n\n\nMaintenant que nous disposons de toutes ces matrices, nous pouvons calculer le *I* de Moran global pour chaque matrice.\n\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(spdep)\n## Calcul du I de Moran pour les différentes matrices\nmoran_vals <- sapply(all_matrices, function(W){\n  # Petite conversion vers le type de spdep\n  attr(W,'class') <- c(\"listw\", \"nb\")\n  W$style <- \"W\"\n  W$neighbours <- W$nb_list\n  W$nb_list <- NULL\n  val <- moran(lixels$density_adpt_knn, listw = W,\n        n = nrow(lixels),\n        S0 = nrow(lixels),\n        zero.policy = TRUE)\n  return(val$I)\n})\n## Enregistrement dans un dataframe\ndf_moran <- data.frame(\n  Matrices = names(all_matrices),\n  MoranIs = moran_vals\n)\n## Réalisation d'un graphique\nggplot(data=df_moran, aes(x=reorder(Matrices,MoranIs), y=MoranIs)) +\n  geom_segment( aes(x=reorder(Matrices,MoranIs), \n                    xend=reorder(Matrices,MoranIs), \n                    y=0, yend=MoranIs)) +\n  geom_point( size=4,fill=\"red\",shape=21)+\n  xlab(\"Matrice de pondération spatiale sur le réseau\") +\n  ylab(\"I de Moran\")+\n  coord_flip()\n```\n\n::: {.cell-output-display}\n![*I* de Moran obtenu pour différentes matrices de pondération spatiale sur réseau](06-AnalyseReseauEvenements_files/figure-pdf/fig-moranIGlobNKDE-1.pdf){#fig-moranIGlobNKDE fig-align='center' fig-pos='H' width=85%}\n:::\n:::\n\n\n\n\n\n\nÀ la @fig-moranIGlobNKDE, nous constatons que la matrice utilisant les trois plus proches voisins obtient la valeur du *I* de Moran la plus élevé. Nous la conservons pour calculer la mesure d'autocorrélation spatiale locale basée sur la typologie basée sur le diagramme de Moran (@fig-localMoranNKDE).\n\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nW <- all_matrices$k_mat_3\nattr(W,'class') <- c(\"listw\", \"nb\")\nW$style <- \"W\"\nW$neighbours <- W$nb_list\nW$nb_list <- NULL\nlocal_I <- localmoran(lixels$density_adpt, listw = W, zero.policy = TRUE)\nlixels$loc_classes <- attributes(local_I)$quadr$mean\nlixels$loc_p <- local_I[,5]\nlixels$loc_classes2 <- case_when(\n  lixels$loc_p < 0.01 ~ lixels$loc_classes,\n  TRUE ~ 'non sign.'\n)\nCouleurs <- c(\"High-High\" = \"#FF0000\",\n              \"Low-Low\" =\"#0000FF\",\n              \"High-Low\" = \"#f4ada8\",\n               \"Low-High\" =\"#a7adf9\",\n              'non sign.' = \"#eeeeee\")\ntm_shape(lixels) + \n  tm_lines('loc_classes2', palette = Couleurs,\n           lwd = 1.2, title.col = \"Typologie\")\n```\n\n::: {.cell-output-display}\n![Typologie basée sur le diagramme de Moran](06-AnalyseReseauEvenements_files/figure-pdf/fig-localMoranNKDE-1.pdf){#fig-localMoranNKDE fig-align='center' fig-pos='H' width=85%}\n:::\n:::\n\n\n\n\n\n\n::: bloc_aller_loin\n::: bloc_aller_loin-header\n::: bloc_aller_loin-icon\n:::\n\n**Mesures d'autocorrélation spatiale globale et locale sur un réseau**\n:::\n\n::: bloc_aller_loin-body\nAu [chapitre @sec-chap02], nous avons vu une panoplie de mesures d'autocorrélation spatiale globale ([section @sec-023]) et locale ([section @sec-024]) calculées avec différentes matrices de pondération spatiale ([section @sec-022]).\n\nOr, n'importe quelle mesure d'autocorrélation spatiale peut être calculée à partir d'une matrice de pondération spatiale construite à partir des distances réseau. Retenez que le choix de la matrice reste un enjeu important puisqu'elle affecte significativement les résultats comme illustré à la @fig-moranIGlobNKDE.\n:::\n:::\n\n## DBSCAN sur un réseau {#sec-064}\n\nDans la [section @sec-0411], Nous avons vu l'algorithme DBSCAN détectant des agrégats de points dans l'espace. Cet algorithme de classification non supervisée basée sur la densité des points identifie des agrégats de points à partir de deux paramètres : un rayon de recherche ($\\epsilon$, epsilon) et un nombre minimum de points ($MinPts$). Il est assez facile d'adapter cette méthode afin que le rayon de recherche ne soit pas basée sur la distance euclidienne, mais plutôt sur la distance réseau. Cela est particulièrement pertinent lors les évènements sont localisés sur un réseau, comme des accidents routiers.\n\n### Mise en œuvre dans R {#sec-0642}\n\nPour illustrer la version réseau du DBSCAN, nous reprenons l'exemple de la [section @sec-0414] basé sur un [jeu de données sur les incidents de sécurité publique survenus sur le territoire de la ville de Sherbrooke de juillet 2019 à juin 2022](https://donneesouvertes-sherbrooke.opendata.arcgis.com/datasets/64d19d62f0804f5896e4b24c32aea49d_0/explore?location=45.403675%2C-71.960143%2C12.65).\n\nTout d'abord, nous importons les couches géographiques des accidents et du réseau routier (@fig-AccidentsReseauDBSCAN).\n\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(sf)\nlibrary(tmap)\nlibrary(spNetwork)\nlibrary(dbscan)\nlibrary(ggplot2)\nlibrary(spdep)\n## Importation des accidents\nAccidents.sf <- st_read(dsn = \"data/chap04/DataAccidentsSherb.shp\", quiet=TRUE)\n## Importation des routes (réseau)\nroutes <- st_read('data/chap01/shp/Segments_de_rue.shp', quiet=TRUE)\n# reprojection dans le même système\nroutes <- st_transform(routes, 32187)\nAccidents.sf <- st_transform(Accidents.sf, 32187)\nroutes <- sf::st_cast(routes, 'LINESTRING')\ntm_shape(routes) + \n  tm_lines('black') + \n  tm_shape(Accidents.sf) + \n  tm_dots('red', size = 0.2)\n```\n\n::: {.cell-output-display}\n![Accidents sur le réseau de la ville de Sherbrooke](06-AnalyseReseauEvenements_files/figure-pdf/fig-AccidentsReseauDBSCAN-1.pdf){#fig-AccidentsReseauDBSCAN fig-align='center' fig-pos='H' width=75%}\n:::\n:::\n\n\n\n\n\n\nPuis, nous recherchons la valeur optimale d'epsilon ($\\epsilon$) avec un nombre minimal de quatre points ($MinPts$) pour former un agrégat. À la lecture de la @fig-GraphiqueAccidentsNetDist4, nous constatons que le coude se situe certainement entre 750 et 1250 mètres.\n\n::: bloc_attention\n::: bloc_attention-header\n::: bloc_attention-icon\n:::\n\n**Matrice de pondération spatiales des distances réseau avec `spNetwork` et `spdep`**\n:::\n\n::: bloc_attention-body\nDans le code ci-dessous, les distances réseau sont obtenues avec le *package* `spNetwork`, sous forme d'un objet de type `listw`. Elles sont ensuite converties en matrice avec la fonction `listw2mat` du *package* `spdep`, et enfin en objet de type `distance` avec la fonction `as.dist`. Si le nombre de points à analyser est très grand, la matrice de distances pourrait excéder la mémoire vive disponible dans votre ordinateur.\n:::\n:::\n\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n## Calcul des distances pour les quatre plus proches voisins\nknn_dists <- network_knn(origins = Accidents.sf,\n                         lines = routes,\n                         k = 4,\n                         maxdistance = 5000,\n                         grid_shape = c(1,1),\n                         verbose = FALSE)\n## Graphique pour la distance au quatrième voisin le plus proche\ndists4 <- knn_dists$distances[,4]\ndists4 <- dists4[order(dists4)]\nDistKplusproche <- data.frame(\n  distance = dists4,\n  id = 1:length(dists4)\n)\nggplot(data = DistKplusproche)+\n  geom_path(aes(x = id, y = distance), size=1)+\n  labs(x = \"Points triés par ordre croissant selon la distance\",\n       y = \"Distance au quatrième point le plus proche\")+\n  geom_hline(yintercept=250, color = \"#08306b\", linetype=\"dashed\", size=1)+\n  geom_hline(yintercept=500, color = \"#00441b\", linetype=\"dashed\", size=1)+\n  geom_hline(yintercept=1000, color = \"#67000d\", linetype=\"dashed\", size=1)+\n  geom_hline(yintercept=1500, color = \"#3f007d\", linetype=\"dashed\", size=1)\n```\n\n::: {.cell-output-display}\n![Optimisation de la valeur d’epsilon pour les accidents sur réseau](06-AnalyseReseauEvenements_files/figure-pdf/fig-GraphiqueAccidentsNetDist4-1.pdf){#fig-GraphiqueAccidentsNetDist4 fig-align='center' fig-pos='H' width=65%}\n:::\n:::\n\n\n\n\n\n\nLa comparaison des figures [-@fig-DBSCANCarto250], [-@fig-DBSCANCarto500], [-@fig-DBSCANCarto1000] et [-@fig-DBSCANCarto1500] montre clairement qu'au-delà de 1000 mètres, les résultats sont assez peu intéressants, car presque tous les points sont agrégés dans le même groupe.\n\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n## Calcul des distances réseau entre chaque évènement\nnetwork_dists <- network_listw(origins = Accidents.sf,\n                               lines = routes,\n                               maxdistance = 5000,\n                               mindist = 1,\n                               dist_func = \"identity\",\n                               matrice_type = \"I\",\n                               grid_shape = c(1,1))\n\nnetwork_dists$neighbours <- network_dists$nb_list\nnetwork_dists_matrix <- listw2mat(network_dists)\n\n# 0 signifie que la distance entre les deux points \n# est plus grande que le paramètre maxdistance\nnetwork_dists_matrix <- ifelse(network_dists_matrix == 0,\n                               5000, network_dists_matrix)\nnetwork_dists_matrix <- as.dist(network_dists_matrix)\n\n# Algorithme dbscan avec les différentes valeurs d'epsilon\nresult250 <- dbscan(network_dists_matrix, eps = 250, minPts = 4)\nresult500 <- dbscan(network_dists_matrix, eps = 500, minPts = 4)\nresult1000 <- dbscan(network_dists_matrix, eps = 1000, minPts = 4)\nresult1500 <- dbscan(network_dists_matrix, eps = 1500, minPts = 4)\nAccidents.sf$gp_250 <- as.character(result250$cluster)\nAccidents.sf$gp_500 <- as.character(result500$cluster)\nAccidents.sf$gp_1000 <- as.character(result1000$cluster)\nAccidents.sf$gp_1500 <- as.character(result1500$cluster)\n\n# Cartographie\ntmap_options(max.categories = 50)\ntm_shape(Accidents.sf)+tm_dots(col=\"gp_250\", title = \"DBSCAN 250\", size = .5)\n```\n\n::: {.cell-output-display}\n![Résultats obtenus pour le dbscan avec un valeur d'epsilon de 250 mètres](06-AnalyseReseauEvenements_files/figure-pdf/fig-DBSCANCarto250-1.pdf){#fig-DBSCANCarto250 fig-align='center' fig-pos='H' width=85%}\n:::\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ntm_shape(Accidents.sf)+tm_dots(col=\"gp_500\", title = \"DBSCAN 500\", size = .5)\n```\n\n::: {.cell-output-display}\n![Résultats obtenus pour le dbscan avec un valeur d'epsilon de 500 mètres](06-AnalyseReseauEvenements_files/figure-pdf/fig-DBSCANCarto500-1.pdf){#fig-DBSCANCarto500 fig-align='center' fig-pos='H' width=85%}\n:::\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ntm_shape(Accidents.sf)+tm_dots(col=\"gp_1000\", title = \"DBSCAN 1000\", size = .5)\n```\n\n::: {.cell-output-display}\n![Résultats obtenus pour le dbscan avec un valeur d'epsilon de 1000 mètres](06-AnalyseReseauEvenements_files/figure-pdf/fig-DBSCANCarto1000-1.pdf){#fig-DBSCANCarto1000 fig-align='center' fig-pos='H' width=85%}\n:::\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ntm_shape(Accidents.sf)+tm_dots(col=\"gp_1500\", title = \"DBSCAN 1500\", size = .5)\n```\n\n::: {.cell-output-display}\n![Résultats obtenus pour le dbscan avec un valeur d'epsilon de 1500 mètres](06-AnalyseReseauEvenements_files/figure-pdf/fig-DBSCANCarto1500-1.pdf){#fig-DBSCANCarto1500 fig-align='center' fig-pos='H' width=85%}\n:::\n:::\n\n\n\n\n\n\n## Quiz de révision du chapitre {#sec-065}\n\n\n\n\n\n\n**Questions**\n\n* **Quels problèmes posent l'utilisation des méthodes classiques d'analyse spatiale pour des données se produisant sur un réseau?**\n\t+ La distance euclidienne tend à sous-estimer les distances réelles.\n\t+ La distance euclidienne tend à surestimer les distances réelles.\n\t+ Le réseau est un espace comportant davantage de dimensions qu'un espace planaire.\n\t+ Le réseau est un espace ne respectant pas les hypothèses d'homogénéité et d'isotropie de l'espace planaire.\n\t+ Les méthodes classiques analysent des portions de l'espace en dehors du réseau.\n\n\tRelisez au besoin la [section @sec-061].\n\n* **Pour adapter la méthode classique du Kernel Density Estimate, il est nécessaire de :**\n\t+ Utiliser une distance réseau plutôt qu'euclidienne.\n\t+ N'estimer les densités que le long des lixels représentant des fragments réguliers du réseau.\n\t+ Adapter la fonction de Kernel pour tenir compte de la division de la masse aux intersections.\n\t+ Appliquer une pénalité aux portions du réseau avec peu d'évènements.\n\n\tRelisez au besoin le début de la [section @sec-062].\n\n* **Pour une NKDE, il est uniquement possible de calculer des densités selon une bandwidth fixe.**\n\t+ Vrai\n\t+ Faux\n\n\tRelisez au besoin la [section @sec-06213].\n\n* **Contrairement à la KDE classique, la NKDE est moins sensible au choix de la bandwidth.**\n\t+ Vrai\n\t+ Faux\n\n\tRelisez au besoin la [section @sec-06214].\n\n* **L'extension spatio-temporelle du NKDE (TNKDE) consiste à :**\n\t+ Calculer une somme des densités spatiales et temporelles des évènements le long du réseau.\n\t+ Calculer le produit des densités spatiales et temporelles des évènements le long du réseau.\n\t+ Calculer l'intégrale des densités spatiales et temporelles des évènements le long du réseau.\n\n\tRelisez au besoin la [section @sec-0623].\n\n* **Pour une TNKDE, il est uniquement possible de calculer des densités selon une bandwidth fixe.**\n\t+ Vrai\n\t+ Faux\n\n\tRelisez au besoin la [section @sec-0621].\n\n* **Les méthodes KDE, NKDE, et TNKDE peuvent être vues comme :**\n\t+ Des méthodes descriptives visant à résumer un grand ensemble d'évènements en une carte de chaleur plus facilement interprétable.\n\t+ Des méthodes inférentielles permettant de déterminer statistiquement la présence de points chauds ou de points froids.\n\t+ Des algorithmes de type boite noire réduisant la dimensionnalité des données.\n\n\tRelisez au besoin la [section @sec-062].\n\n* **L'utilisation d'une distance réseau plutôt qu'euclidienne pour un algorithme DBSCAN risque de :**\n\t+ Augmenter la taille des groupes détectés par l'algorithme, car la recherche de voisin sera plus facile sur le réseau\n\t+ Réduire la taille des groupes formés par l'algorithme, car la distance euclidienne tend à sous-estimer les distances réelles sur le réseau\n\n\tRelisez au besoin la [section @sec-064].\n\n\n**Réponses**\n\n * Quels problèmes posent l'utilisation des méthodes classiques d'analyse spatiale pour des données se produisant sur un réseau?\n\t+ La distance euclidienne tend à sous-estimer les distances réelles.\n\t+ Le réseau est un espace ne respectant pas les hypothèses d'homogénéité et d'isotropie de l'espace planaire.\n\t+ Les méthodes classiques analysent des portions de l'espace en dehors du réseau.\n * Pour adapter la méthode classique du Kernel Density Estimate, il est nécessaire de :\n\t+ Utiliser une distance réseau plutôt qu'euclidienne.\n\t+ N'estimer les densités que le long des lixels représentant des fragments réguliers du réseau.\n\t+ Adapter la fonction de Kernel pour tenir compte de la division de la masse aux intersections.\n * Pour une NKDE, il est uniquement possible de calculer des densités selon une bandwidth fixe.\n\t+ Faux\n * Contrairement à la KDE classique, la NKDE est moins sensible au choix de la bandwidth.\n\t+ Faux\n * L'extension spatio-temporelle du NKDE (TNKDE) consiste à :\n\t+ Calculer le produit des densités spatiales et temporelles des évènements le long du réseau.\n * Pour une TNKDE, il est uniquement possible de calculer des densités selon une bandwidth fixe.\n\t+ Faux\n * Les méthodes KDE, NKDE, et TNKDE peuvent être vues comme :\n\t+ Des méthodes descriptives visant à résumer un grand ensemble d'évènements en une carte de chaleur plus facilement interprétable.\n * L'utilisation d'une distance réseau plutôt qu'euclidienne pour un algorithme DBSCAN risque de :\n\t+ Réduire la taille des groupes formés par l'algorithme, car la distance euclidienne tend à sous-estimer les distances réelles sur le réseau\n\n\n\n\n\n\n## Exercices de révision {#sec-066}\n\n::: bloc_exercice\n::: bloc_exercice-header\n::: bloc_exercice-icon\n:::\n\n**Exercice 1.** Réalisation d'un graphique pour trouver la valeur de la *bandwidth* optimale\n:::\n\n::: bloc_exercice-body\nUtilisez la fonction *kernel* quadratique et la NKDE continue (ESC-NKDE), contruisez un graphique pour choisir une *bandwidth* avec l'approche par validation croisée des probabilités. Complétez le code ci-dessous.\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(sf)\nlibrary(spNetwork)\nlibrary(future)\n\nfuture::plan(future::multisession(workers = 5))\n# Importation des données sur les collisions cycles et le réseau de rues\nCollisions <- st_read(dsn = \"data/chap06/Mtl/DonneesMTL.gpkg\", layer=\"CollisionsAvecCyclistes\", quiet=TRUE)\nReseauRues <- st_read(dsn = \"data/chap06/Mtl/DonneesMTL.gpkg\", layer=\"Rues\", quiet=TRUE)\nReseauRues$LineID <- 1:nrow(ReseauRues)\nLongueurKm <- sum(as.numeric(st_length(ReseauRues)))/1000\nCollisions <- st_transform(Collisions, st_crs(ReseauRues))\ncat(\"Informations sur les couches\",\n    \"\\n  Collisions avec cylistes :\", nrow(Collisions),\n    \"\\n  Réseau :\", round(LongueurKm,3), \"km\")\n# Cartographie\ntmap_mode(\"view\")\ntm_shape(ReseauRues) + tm_lines(\"black\") +\n  tm_shape(Collisions) + tm_dots(\"blue\", size = 0.025)+\ntm_scale_bar(c(0,1,2), position = 'left')+\n  tm_layout(frame = FALSE)\n## Évaluation des bandwidths de 100 à 1200 avec un saut de 50\neval_bandwidth <- bw_cv_likelihood_calc.mc(à compléter)\n## Graphique pour les bandwidths \nà compléter\n```\n:::\n\n\n\n\n\n\nCorrection à la [section @sec-12061].\n:::\n:::\n\n::: bloc_exercice\n::: bloc_exercice-header\n::: bloc_exercice-icon\n:::\n\n**Exercice 2.** Réalisation d'une NKDE continue.\n:::\n\n::: bloc_exercice-body\nComplétez le code ci-dessous pour réaliser une NKDE continue avec un fonction *kernel* quadratique et une valeur de *bandwidth* de 500 mètres.\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(sf)\nlibrary(spNetwork)\nlibrary(future)\n## Création des lixels d'une longueur de 100 mètres\nlixels <- lixelize_lines(ReseauRues, 100, mindist = 50)\nlixels_centers <- spNetwork::lines_center(lixels)\n## Calcul de la NKDE continue\nintensity <- nkde.mc(À compléter)\nlixels$density <- intensity * 1000\n## Cartographie\nÀ compléter\n```\n:::\n\n\n\n\n\n\nCorrection à la [section @sec-12062].\n:::\n:::\n",
    "supporting": [
      "06-AnalyseReseauEvenements_files\\figure-pdf"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {
      "knitr": [
        "{\"type\":\"list\",\"attributes\":{},\"value\":[]}"
      ]
    },
    "preserve": null,
    "postProcess": false
  }
}