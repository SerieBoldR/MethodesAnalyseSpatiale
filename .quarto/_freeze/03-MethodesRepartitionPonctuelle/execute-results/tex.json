{
  "hash": "df2d4052b5f1b0bc282bb5b0a9da512e",
  "result": {
    "engine": "knitr",
    "markdown": "# Méthodes de répartition ponctuelle {#sec-chap03}\n\nDans ce chapitre, nous abordons les méthodes de répartition ponctuelle qui permettent de décrire un semis de points dans un espace géographique donné. En géomatique appliquée, ces méthodes sont fréquemment employées dans le cadre d'études rattachées à des champs disciplinaires variés comme :\n\n-   En études urbaines, pour décrire la répartition de services et d'équipements collectifs à travers une ville afin de vérifier s'ils sont équitablement répartis ou à l'inverse, concentrés dans certaines parties de la ville.\n-   En biologie, pour décrire la répartition d'espèces fauniques ou végétales dans un territoire.\n-   En criminologie, pour analyser la répartition spatiale d'un ou de plusieurs types de crimes.\n-   En épidémiologie, pour comprendre l'évolution de la répartition spatiale des cas d'une maladie infectieuse.\n-   En transport, pour analyser la répartition d'accidents.\n-   Et même en sciences de l'activité physique, pour analyser la distribution spatiale de personnes pratiquant un sport sur un terrain de soccer, de rugby, de tennis, de baseball, etc.\n\n::: bloc_package\n::: bloc_package-header\n::: bloc_package-icon\n:::\n\n**Liste des *packages* utilisés dans ce chapitre**\n:::\n\n::: bloc_package-body\n-   Pour importer et manipuler des fichiers géographiques :\n    -   `sf` pour importer et manipuler des données vectorielles.\n-   Pour construire des cartes et des graphiques :\n    -   `tmap` pour construire des cartes thématiques.\n    -   `ggplot2` est un *package* pour construire des graphiques.\n-   Pour les analyses de méthodes de répartition ponctuelle :\n    -   `spatstat` est sans aucun doute le meilleur *package*.\n    -   `sparr` pour calculer la STKDE, soit l'estimation de la densité par noyau spatio-temporel (*Space-Time Kernel density Estimatation*).\n:::\n:::\n\n::: bloc_objectif\n::: bloc_objectif-header\n::: bloc_objectif-icon\n:::\n\n**Pour décrire la distribution d'un semis de points, nous voyons les méthodes suivantes :**\n:::\n\n::: bloc_objectif-body\n-   La fréquence et la densité des points dans l'espace d'étude.\n-   L'analyse centrographique :\n    -   Paramètres de tendance centrale (centre moyen et point central).\n    -   Dispersion du semis de points (distance standard) et ses différentes représentations graphiques (cercle et ellipse de distance standard).\n-   L'arrangement spatial du semis de points :\n    -   Méthode du plus proche voisin.\n    -   Méthode des quadrats.\n-   La cartographie de la densité :\n    -   Dans une maille irrégulière (des polygones de forme et de taille différentes).\n    -   Dans une maille régulière (estimation de la densité par noyau -- *kernel density estimation, KDE*).\n:::\n:::\n\n## Fréquence et densité des points dans l'espace d'étude {#sec-031}\n\nLa **fréquence** est tout simplement le nombre de points présents dans une région donnée (par exemple, le nombre d'hôpitaux, de stations de métro, d'arbres, etc.). La **densité** est le ratio entre la fréquence et la *superficie totale* de la région donnée ou la *population*.\n\nPar exemple, le @tbl-TableauMetros renvoie le nombre et la densité des stations de métro (pour 10 000 habitants) pour trois villes. Interprétez ces chiffres avec prudence, car ils varient en fonction de la taille du territoire retenu pour les trois villes.\n\n\n\n\n\n\n::: {#tbl-TableauMetros .cell tbl-cap='Fréquence et densité des stations de métro dans trois villes'}\n::: {.cell-output-display}\n\n\n|Ville           |Population | Stations de métro| Densité (stations / 10 000 hab.) |\n|:---------------|:----------|-----------------:|:--------------------------------:|\n|New York        |8 804 000  |               424|               0,5                |\n|Paris           |2 165 000  |               309|               1,4                |\n|Île de Montréal |2 004 000  |                68|               0,3                |\n\n\n:::\n:::\n\n\n\n\n\n\n## Analyse centrographique {#sec-032}\n\nL'analyse centrographique est une approche qui a été largement utilisée durant les décennies 1990 et 2000. Son utilisation est parfois critiquée pour deux raisons principales : 1) elle ne décrit que partiellement le semis de points; 2) aucun test d'inférence n'est calculé. Quoi qu'il en soit, elle permet d'explorer les données avant de se lancer dans des analyses plus avancées.\n\n::: bloc_notes\n::: bloc_notes-header\n::: bloc_notes-icon\n:::\n\n**Utilisation de l'analyse centrographique au Québec et dans le monde francophone**\n:::\n\n::: bloc_notes-body\nMarius Thériault (géographe et professeur émérite à l'Université Laval) a largement contribué à la popularité de l'analyse centrographique au Québec et ailleurs. Il est le créateur de *MapStat*, un module développé avec le langage MapBasic intégré dans le logiciel SIG MapInfo permettant de réaliser une analyse centrographique avant même qu'elle soit implémentée dans ArcGIS. En guise d'exemple, les études suivantes utilisent l'analyse centrographique calculée avec *MapStat* [@lopez2015evolution; @barbonne2007dynamique]. Consultez-les au besoin.\n:::\n:::\n\n### Paramètres de tendance centrale d'un semis de points {#sec-0311}\n\nLes deux principaux paramètres de tendance centrale d'un semis de points sont le centre moyen et le point central qui peuvent être ou non pondérés.\n\n#### Centre moyen {#sec-03111}\n\nLe centre moyen ($cm$) est le centre de gravité du semis de points et correspond aux valeurs des moyennes arithmétiques des coordonnées géographiques (@eq-CentreMoyen).\n\n$$\n(\\bar{x}_{cm}, \\bar{y}_{cm}) = \\Biggl( \\frac{\\Sigma_{i=1}^n x_i}{n}, \\frac{\\Sigma_{i=1}^n y_i}{n}\\Biggl)\\text{ avec :}\n$$ {#eq-CentreMoyen}\n\n-   $(\\bar{x}_{cm}, \\bar{y}_{cm})$, les coordonnées géographiques du point moyen.\n-   $n$, le nombre de points dans la couche géographique.\n-   $x_i$ et $y_j$, les coordonnées géographiques du point $i$.\n\nIl est possible de calculer le centre moyen en pondérant chacun des points du semis avec la valeur d'une variable donnée (@eq-CentreMoyenPonderee). Ainsi, l'importance accordée à chacun des points n'est pas la même. Par exemple, nous pourrions calculer le centre moyen pondéré ($cmp$) des cliniques médicales d'une ville en pondérant chaque clinique par le nombre de médecins, ou encore le point moyen des hôpitaux pondéré par le nombre de lits. Autre exemple, avec un jeu de données sur les arbres dans une érablière, nous pourrions utiliser une pondération basée sur le diamètre à la hauteur de la poitrine (DHP) afin d'accorder un poids plus important aux arbres de plus « grand volume ».\n\n::: bloc_notes\n::: bloc_notes-header\n::: bloc_notes-icon\n:::\n\n**Moyenne pondérée**\n:::\n\n::: bloc_notes-body\n**Pour un rappel sur le calcul d'une moyenne pondérée**, consultez la section intitulée [*Statistiques descriptives pondérées*](https://serieboldr.github.io/MethodesQuantitatives/02-univarie.html#sec-027) [@RBoldAir].\n:::\n:::\n\n$$\n(\\bar{x}_{cmp}, \\bar{y}_{cmp}) = \\Biggl( \\frac{\\Sigma_{i=1}^n w_ix_i}{\\Sigma_{i=1}^nw_i}, \\frac{\\Sigma_{i=1}^n w_iy_i}{\\Sigma_{i=1}^nw_i}\\Biggl) \\text{ avec :}\n$$ {#eq-CentreMoyenPonderee}\n\n-   $n$, $x_i$ et $y_j$ étant définis plus haut.\n-   $(\\bar{x}_w, \\bar{y}_w)$, les coordonnées géographiques du point moyen pondéré.\n-   $w_i$, la valeur de pondération associée au point $i$.\n\nLe centre moyen et le centre moyen pondéré sont des mesures très utiles pour comparer la distribution de plusieurs semis de points (de différents services et équipements collectifs par exemple) ou encore pour décrire l'évolution dans le temps de la répartition d'un semis de points. L'analyse du déplacement du centre moyen (pondéré) à différentes dates nous informe ainsi de l'évolution du phénomène à l'étude et plus spécifiquement, de son orientation et de sa direction.\n\n::: bloc_astuce\n::: bloc_astuce-header\n::: bloc_astuce-icon\n:::\n\n**Exemple d'utilisation temporelle du centre moyen pondéré**\n:::\n\n::: bloc_astuce-body\nUn exemple classique d'utilisation du centre moyen pondéré sur plusieurs années est l'évolution du centre moyen pondéré de la population des États-Unis de 1790 à 2020. Il est calculé à partir des centroïdes des comtés américains et de la population comme variable de pondération extraite des recensements de l'*US Census Bureau*. Bien entendu, le centre moyen pondéré se déplace vers l'ouest.\n\nVous pouvez consulter [cette carte](https://www.census.gov/library/visualizations/2020/geo/center-of-population-1790-2020.html) ou visionner cette [courte vidéo YouTube ludique](https://www.youtube.com/watch?v=D9XelnGyggI).\n:::\n:::\n\nNotez que les centres moyen et moyen pondéré peuvent aussi être calculés sur des données géographiques comprenant des valeurs d'élévation ($x,y,z$) :\n\n$$\n(\\bar{x}_{cm}, \\bar{y}_{cm}, \\bar{z}_{cm}) = \\Biggl( \\frac{\\Sigma_{i=1}^n x_i}{n}, \\frac{\\Sigma_{i=1}^n y_i}{n}, \\frac{\\Sigma_{i=1}^n z_i}{n}\\Biggl)\n$$ {#eq-PointMoyenZ1}\n\n$$\n(\\bar{x}_{cmp}, \\bar{y}_{cmp}, \\bar{z}_{cmp}) = \\Biggl( \\frac{w_i\\Sigma_{i=1}^n x_i}{\\Sigma_{i=1}^nw_i}, \\frac{w_i\\Sigma_{i=1}^n y_i}{\\Sigma_{i=1}^nw_i}, \\frac{w_i\\Sigma_{i=1}^n z_i}{\\Sigma_{i=1}^nw_i}\\Biggl)\n$$ {#eq-PointMoyenZ2}\n\n#### Point central {#sec-03112}\n\nLe point central d'un semis de points est celui qui minimise la somme des distances le séparant de tous les autres points (@eq-PointCentral). Tout comme le point moyen, il est aussi possible de calculer le point central pondéré (@eq-PointCentralW).\n\n$$\npc=\\text{Min}\\Biggl(\\Sigma_{i=1}^n \\sqrt{(x_i-x_j)^2+(y_i-y_j)^2}\\Biggl)\\text{; avec }i \\ne j\n$$ {#eq-PointCentral}\n\n$$\npcp=\\text{Min}\\Biggl(\\Sigma_{i=1}^n w_i \\sqrt{(x_i-x_j)^2+(y_i-y_j)^2}\\Biggl)\\text{; avec }i \\ne j\n$$ {#eq-PointCentralW}\n\n::: bloc_attention\n::: bloc_attention-header\n::: bloc_attention-icon\n:::\n\n**Différence entre point central et centre moyen**\n:::\n\n::: bloc_attention-body\nContrairement au centre moyen, le point central fait partie du semis de points initial.\n\n**Utilité du point central pondéré**\n\nImaginez que des personnes étudiantes en géographie et en géomatique de toutes les universités du Québec souhaitent organiser une rencontre en présence. Calculer le point central, pondéré par le nombre de personnes étudiantes par établissement participant à la rencontre, permet d'identifier l'université la plus centrale. Idéalement, il faudrait obtenir ce point central pondéré avec les distances temps calculées avec un réseau routier.\n:::\n:::\n\n### Paramètres de dispersion d'un semis de points {#sec-0312}\n\nLes deux principaux paramètres de dispersion d'un semis de points sont la distance standard et la distance standard pondérée. La dispersion d'un semis de points peut être représentée graphiquement avec une enveloppe convexe, un cercle de rayon de standard ou une ellipse (avec ou sans pondération).\n\n#### Distance standard et distance standard pondérée {#sec-03121}\n\nEn statistique univariée, l'écart-type (@eq-ecartype) est une mesure de dispersion bien connue : plus la valeur de l'écart-type est élevée, plus la dispersion des valeurs de la variable autour de la moyenne ($\\mu$) est importante.\n\n$$\n\\sigma=\\sqrt{\\frac{\\sum_{i=1}^n (x_{i}-\\mu)^2}{n}}\n$$ {#eq-ecartype}\n\n::: bloc_notes\n::: bloc_notes-header\n::: bloc_notes-icon\n:::\n\n**Écart-type**\n:::\n\n::: bloc_notes-body\n**Pour un rappel sur l'écart-type**, consultez la section intitulée [*Paramètres de dispersion*](https://serieboldr.github.io/MethodesQuantitatives/02-univarie.html#sec-0253) [@RBoldAir].\n:::\n:::\n\n**Distance standard (pondérée ou non) des *X* et des *Y***\n\nDe manière analogue à l'écart-type, nous pouvons calculer la distance standard pour les coordonnées *X* et pour les coordonnées *Y* des points, soit l'écart moyen respectif au centre moyen (@eq-distancestandardxy) ou au centre moyen pondéré (@eq-distancestandardxyw).\n\n$$\n\\sigma_x=\\sqrt{\\frac{\\sum_{i=1}^n (x_{i}-\\bar{x}_{cm})^2}{n}} \\text{ et } \n\\sigma_y=\\sqrt{\\frac{\\sum_{i=1}^n (y_{i}-\\bar{y}_{cm})^2}{n}}\n$$ {#eq-distancestandardxy}\n\n$$\n\\sigma_{xw}=\\sqrt{\\frac{\\sum_{i=1}^n w_i(x_{i}-\\bar{x}_{cmp})^2}{\\sum_{i=1}^n{w_i}}} \\text{ et } \\sigma_{yw}=\\sqrt{\\frac{\\sum_{i=1}^n w_i(y_{i}-\\bar{y}_{cmp})^2}{\\sum_{i=1}^n{w_i}}}\n$$ {#eq-distancestandardxyw}\n\n**Distance standard (pondérée ou non)**\n\nNous pouvons aussi calculer la distance standard ($ds$) sans pondération (@eq-distancestandard) et avec pondération (@eq-distancestandardw). Plus elle est forte, plus les points sont dispersés autour du centre moyen ou du centre moyen pondéré. Inversement, une faible distance standard indique une concentration de points autour du centre moyen.\n\n$$\nds=\\sqrt{\\frac{\\sum_{i=1}^n (x_{i}-\\bar{x}_{cm})^2}{n} + \\frac{\\sum_{i=1}^n (y_{i}-\\bar{y}_{cm})^2}{n}}\n$$ {#eq-distancestandard}\n\n$$\nds_w=\\sqrt{\\frac{\\sum_{i=1}^n w_i(x_{i}-\\bar{x}_{cmp})^2}{\\sum_{i=1}^n w_i} + \\frac{\\sum_{i=1}^n w_i(y_{i}-\\bar{y}_{cmp})^2}{\\sum_{i=1}^n w_i}}\n$$ {#eq-distancestandardw}\n\nDe nouveau, ces mesures peuvent être adaptées pour des points avec une élévation ($x,y,z$) :\n\n$$\nds=\\sqrt{\\frac{\\sum_{i=1}^n (x_{i}-\\bar{x}_{cm})^2}{n} + \\frac{\\sum_{i=1}^n (y_{i}-\\bar{y}_{cm})^2}{n} + \\frac{\\sum_{i=1}^n (z_{i}-\\bar{z}_{cm})^2}{n}}\n$$ {#eq-distancestandardz}\n\n$$\nds_w=\\sqrt{\\frac{\\sum_{i=1}^n w_i(x_{i}-\\bar{x}_{cmp})^2}{\\sum_{i=1}^n w_i} + \\frac{\\sum_{i=1}^n w_i(y_{i}-\\bar{y}_{cmp})^2}{\\sum_{i=1}^n w_i} + \\frac{\\sum_{i=1}^n w_i(z_{i}-\\bar{z}_{cmp})^2}{\\sum_{i=1}^n w_i}}\n$$ {#eq-distancestandardwz}\n\n#### Représenter la dispersion : cercle de distance standard et ellipse {#sec-03122}\n\nLa dispersion d'un semis de points peut être représentée de quatre manières différentes :\n\n1.  Une enveloppe convexe des points décrite à la [section @sec-01225]).\n\n2.  Un rectangle centré sur le centre moyen avec les déviations des coordonnées *X* et *Y* pondérées ou non (@eq-distancestandardxy et @eq-distancestandardxyw décrites précédemment). Dans le cas de données comprenant l'élévation, la forme géométrique est un parallélépipède rectangle.\n\n3.  Un cercle de rayon de distance standard pondérée ou non (@eq-distancestandard et @eq-distancestandardw) décrites précédemment). Dans le cas de données comprenant l'élévation, la forme géométrique est une sphère de rayon de distance standard.\n\n4.  Une ellipse de distance standard pondérée ou non. Dans le cas de données comprenant l'élévation, la forme géométrique est un ellipsoïde.\n\n**Prenons un jeu de données fictives** pour décrire ces quatre représentations graphiques. Imaginons que nous avons observé le parc de la Laurentie à Sherbrooke pour comprendre son utilisation. Pour collecter des données sur la localisation des personnes utilisatrices, nous aurions pu utiliser un questionnaire dans QField ou ArcGIS Survey 123. La @fig-PointsB illustre la localisation de dix personnes (points rouges).\n\n![Données fictives sur des personnes utilisatrices du parc de la Laurentie à Sherbrooke](images/Chap03/CartePointsB.png){#fig-PointsB width=\"100%\" fig-align=\"center\"}\n\nÀ partir de ces dix points, nous obtenons :\n\n-   Les coordonnées du **centre moyen** qui sont égales à -8 007 869 et 5 685 921, soit simplement les moyennes des coordonnées *X* et *Y* des dix observations.\n\n-   L'**enveloppe convexe des points** qui contient tous les points.\n\n-   **Le rectangle construit avec les déviations standards des *X* et des *Y*** qui est centré sur le centre moyen. À partir de ce point, nous ajoutons à l'est et à l'ouest la valeur de la distance standard des *X* et au nord et au sud celle des *Y*. Les valeurs de ces distances standards sont égales à 32,60 et 52,20 mètres (voir les calculs au @tbl-DonneesFictivesCasB).\n\n-   La **distance standard** est égale à 61,59 mètres (voir les calculs au @tbl-DonneesFictivesCasB). À partir de cette distance, nous traçons le cercle ayant comme rayon la distance standard.\n\n-   L'**ellipse de déviation de distance standard** (@fig-ExplicationEllipse).\n\n\n\n\n\n\n::: {#tbl-DonneesFictivesCasB .cell tbl-cap='Calcul des distances standards des X et des Y et de la distance standard'}\n::: {.cell-output-display}\n\n\n|         Point|     $x_i$|    $y_i$| $(x_{i}-\\bar{x}_{cm})^2$| $(y_{i}-\\bar{y}_{cm})^2$| $(x_{i}-\\bar{x}_{cm})^2+(y_{i}-\\bar{y}_{cm})^2$|\n|-------------:|---------:|--------:|------------------------:|------------------------:|-----------------------------------------------:|\n|             1|  -8007877|  5686000|                    52,80|                  6347,70|                                         6400,50|\n|             2|  -8007843|  5685993|                   716,90|                  5298,00|                                         6014,90|\n|             3|  -8007836|  5685976|                  1082,00|                  3046,30|                                         4128,30|\n|             4|  -8007859|  5685928|                    98,90|                    60,30|                                          159,20|\n|             5|  -8007911|  5685935|                  1770,20|                   214,60|                                         1984,80|\n|             6|  -8007913|  5685871|                  1934,80|                  2461,00|                                         4395,80|\n|             7|  -8007888|  5685855|                   365,70|                  4363,40|                                         4729,10|\n|             8|  -8007835|  5685857|                  1185,00|                  4016,80|                                         5201,80|\n|             9|  -8007824|  5685886|                  2071,70|                  1203,50|                                         3275,20|\n|            10|  -8007906|  5685904|                  1376,50|                   266,70|                                         1643,30|\n|             n|        10|         |                         |                         |                                                |\n|         Somme| -80078693| 56859207|                 10654,50|                 27278,30|                                        37932,80|\n|       Moyenne|  -8007869|  5685921|                  1065,45|                  2727,83|                                         3793,28|\n| Racine carrée|          |         |                    32,60|                    52,20|                                           61,59|\n\n\n:::\n:::\n\n\n\n\n\n\n![Trois éléments composant une ellipse](images/Chap03/ExplicationEllipse.png){#fig-ExplicationEllipse width=\"35%\" fig-align=\"center\"}\n\n::: bloc_attention\n::: bloc_attention-header\n::: bloc_attention-icon\n:::\n\n**Calcul des ellipses : des résultats qui varient d'un logiciel à l'autre...**\n:::\n\n::: bloc_attention-body\nIl existe plusieurs solutions pour tracer une ellipse. Pour une discussion détaillée de ces différentes solutions, lisez le [court texte très intéressant de Martin Leroux](https://portailsig.org/content/qgis-des-ellipses-de-deviation-standard-sde-un-plugin-standard-deviational-ellipse-des-scrip.html).\n\n-   Ellipse de Yuill [@tveitesde].\n\n-   Ellipse basée sur la covariance implémentée dans [ArcGIS Pro](https://pro.arcgis.com/en/pro-app/3.0/tool-reference/spatial-statistics/h-how-directional-distribution-standard-deviationa.htm).\n\n-   Ellipse de distance standard implémentée dans le logiciel [CrimeStat](https://www.icpsr.umich.edu/CrimeStat/).\n\n-   Ellipse avec la correction proposée par Wang et ses collègues [-@wang2015confidence].\n\nNotez qu'un plugin QGIS nommé *The QGIS Standard Deviational Ellipse Plugin* [@tveitesde] intègre plusieurs de ces méthodes. Les résultats varient ainsi d'un logiciel à l'autre selon la méthode implémentée. Autrement dit, pour un même jeu de données ponctuelles, les ellipses obtenues avec ArcGIS Pro, ArcMap 9.3, ArcMap 10.x et QGIS seront différentes.\n\n**Quoi faire alors?**\n\nQuelle que soit la méthode utilisée, l'ellipse est toujours centrée sur le point moyen et a toujours le même angle de rotation. Par contre, la taille de l'ellipse (superficie) varie. Par conséquent, si vous souhaitez comparer des ellipses différentes, assurez-vous toujours qu'elles sont toutes obtenues dans le même logiciel et avec la même solution.\n:::\n:::\n\n::: bloc_aller_loin\n::: bloc_aller_loin-header\n::: bloc_aller_loin-icon\n:::\n\n**Calcul de l'ellipse selon la méthode implémentée dans CrimeStat**\n:::\n\n::: bloc_aller_loin-body\nNed Levine [-@levine2006crime; -@levine2021crimestat], créateur du logiciel [CrimeStat](https://www.icpsr.umich.edu/CrimeStat/), propose les formulations suivantes pour le calcul d'une ellipse :\n\n$$\n\\theta = \\frac{\\text{arctan} \\Biggl\\{ \\Bigl(\\sum_{i=1}^nx_d^2-\\sum_{i=1}^ny_d^2 \\Bigl)+  \\Bigr[\\Bigl(\\sum_{i=1}^nx_d^2-\\sum_{i=1}^ny_d^2 \\Bigl)^2 + 4 \\Bigl(\\sum_{i=1}^nx_dy_d \\Bigl)^2\\Bigr]^{1/2} \\Biggl\\}} {2 \\sum_{i=1}^nx_dy_d}\n$$ {#eq-CrimeStatRotation}\n\navec $\\theta$ est la rotation de l'ellipse, $x_d = x_i-\\bar{x}$ et $y_d = y_i-\\bar{y}$.\n\n$$\n\\sigma_x =\\sqrt{2\\times \\frac{\\sum_{i=1}^n\\Bigl((x_i-\\bar{x}) \\text{cos}\\theta-(y_i-\\bar{y})\\text{sin}\\theta\\Bigl)^2}{n-2}}\n$$ {#eq-CrimeStatSigmaX}\n\n$$\n\\sigma_y =\\sqrt{2\\times \\frac{\\sum_{i=1}^n\\Bigl((x_i-\\bar{x}) \\text{sin}\\theta-(y_i-\\bar{y})\\text{cos}\\theta\\Bigl)^2}{n-2}}\n$$ {#eq-CrimeStatSigmaY}\n\n$$\nl_x=2\\sigma_x \\text{ et }l_y=2\\sigma_y \\text{ et }S_e=\\pi\\sigma_x\\sigma_y\n$$ {#eq-CrimeStatSuperficieLyLx}\n\navec $l_x$, $l_y$ et $S_e$ étant les longueurs de axes *X* et *Y* et la superficie de l'ellipse.\n:::\n:::\n\nPrenons quatre situations fictives de répartition de dix personnes utilisatrices du parc de la Laurentie à Sherbrooke :\n\n-   **Situation A**. Les observations sont concentrées autour de l'aire de jeu.\n-   **Situation B**. Les observations sont dispersées dans la partie est du parc.\n-   **Situation C**. Les observations sont concentrées dans la partie nord du parc.\n-   **Situation D**. Les observations sont concentrées dans la partie nord du parc, excepté deux observations au sud.\n\n![Données fictives sur des personnes utilisatrices du parc de la Laurentie à Sherbrooke (quatre situations)](images/Chap03/CartePointsABCD.png){#fig-PointsABCD width=\"100%\" fig-align=\"center\"}\n\nLes cercles et les ellipses de distance standard ($ds$) centrés au centre moyen ($cm$) sont représentés à la (@fig-EllipsesCercleABCD).\n\n![Ellipse et cercle de distance standard pour les quatre situations](images/Chap03/CartePointsABCD_DS.png){#fig-EllipsesCercleABCD width=\"100%\" fig-align=\"center\"}\n\n#### Comparaison de la dispersion de deux semis de points dans deux régions différentes {#sec-03123}\n\nPour comparer la dispersion de deux semis de points situés dans des régions de taille différente, il convient de supprimer les effets de taille des deux régions. Pour ce faire, nous divisons la **distance standard** ou la **distance standard pondérée** par la superficie de la région. Cette approche est donc très similaire au [coefficient de variation](https://serieboldr.github.io/MethodesQuantitatives/02-univarie.html#sec-0253) en statistique univariée, soit le rapport entre l'écart-type et la moyenne.\n\nPar exemple, si nous comparons les dispersions des personnes utilisatrices du parc de la Laurentie (0,078 ha) et parc du Mont-Bellevue (409 ha). Inévitablement, la valeur de la distance standard est plus forte pour le parc du Mont-Bellevue que celle du parc de la Laurentie. Il faut donc diviser chaque distance standard par la superficie associée.\n\n#### Comparaison de la dispersion de deux semis de points dans la même région {#sec-03124}\n\nPour comparer la distribution spatiale de deux semis de points situés dans la même région, nous comparons leur cercle ou leur ellipse respective (par exemple, des points représentant des accidents l'été versus l'hiver ou encore deux espèces végétales sur le même territoire).\n\nUne démarche similaire peut être appliquée à deux groupes de population rattachés à des entités polygonales : ils ont la même distribution spatiale si les deux ellipses de distance pondérée se juxtaposent significativement. David W.S. Wong [-@wong1999geostatistics] propose d'ailleurs un indice dénommé *S* basé sur la comparaison des deux ellipses (@eq-WongIndice2Groupes). Le numérateur représente la surface d'intersection entre les deux ellipses tandis que le dénominateur représente leur surface d'union. L'indice varie de 0 à 1, soit respectivement d'une similitude parfaite à une dissemblance la plus grande entre les deux distributions spatiales :\n\n-   Si deux groupes de population ont des distributions spatiales identiques, les ellipses sont les mêmes et donc $E_i \\cap E_j = E_i \\cup E_j = 1$ et $S_{ij} = 1 - 1 = 0$.\n\n-   Si les deux groupes de population ont des distributions spatiales totalement différentes, les ellipses ne se touchent pas, alors $E_i \\cap E_j = 0$ et la valeur de $S = 1 - 0 = 1$.\n\nBien évidemment, cet indice peut être étendu pour comparer les distributions de plus de deux groupes de population simultanément (@eq-WongIndiceNGroupes).\n\n$$\nS_{ij}=1-\\frac{E_i \\cap E_j}{E_i \\cup E_j}\n$$ {#eq-WongIndice2Groupes}\n\n$$\nS=1-\\frac{E_1 \\cap E_2 \\cap E_3 \\cap \\text{…} \\cap E_n}{E_1 \\cup E_2 \\cup E_3 \\cup \\text{…} \\cup E_n}\n$$ {#eq-WongIndiceNGroupes}\n\n**Voyons un exemple concret** : calculons l'indice de Wong [-@wong1999geostatistics] (@eq-WongIndice2Groupes) pour les ellipses de distances standards pondérées par les effectifs de propriétaires et de locataires par secteur de recensement pour la ville de Sherbrooke en 2021 (@fig-CarteProprioLoctaires). D'emblée, nous constatons que les propriétaires ont une distribution plus dispersée que celle des locataires plus présents dans le centre de la ville.\n\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![Propriétaires et locataires dans la ville de Sherbrooke (avec ellipse de distance standard), 2021](03-MethodesRepartitionPonctuelle_files/figure-pdf/fig-CarteProprioLoctaires-1.pdf){#fig-CarteProprioLoctaires fig-align='center' width=85%}\n:::\n:::\n\n\n\n\n\n\nLe code suivant permet d'obtenir l'indice de Wong [-@wong1999geostatistics].\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## Importation des deux ellipses \nE1 <- st_read(dsn = \"data/chap03/EllipseProprio.shp\", quiet=TRUE) \nE2 <- st_read(dsn = \"data/chap03/EllipseLocataire.shp\", quiet=TRUE) \n## Intersection \nInter <- st_intersection(E1, E2)\n## Union\nUnion <- st_union(E1, E2)\n## Calcul de l'indice de Wong\nWong <- 1 - ( as.numeric(st_area(Inter)) / as.numeric(st_area(Union)))\nprint(paste0(\"Valeur de l'indice de Wong : \",round(Wong,3)))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"Valeur de l'indice de Wong : 0.515\"\n```\n\n\n:::\n:::\n\n\n\n\n\n\n### Mise en œuvre de l'analyse centrographique dans R {#sec-0313}\n\n#### Calcul de mesures non pondérées {#sec-03131}\n\nPour illustrer la mise en œuvre des différentes mesures de l'analyse centrographique dans R, nous utilisons un jeu de données ouvertes sur les [incidents de sécurité publique de la ville de Sherbrooke](https://donneesouvertes-sherbrooke.opendata.arcgis.com/datasets/64d19d62f0804f5896e4b24c32aea49d_0/explore?location=45.403468%2C-71.960143%2C12.00). Dans le code ci-dessous, nous importons les données et constituons une couche `sf` par année (2019 à 2022) et extrayons les coordonnées géographiques.\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(sf)\nlibrary(tmap)\n## Importation des données \nArrondissements <-  st_read(dsn = \"data/chap03/Arrondissements.shp\", quiet=TRUE)\nIncidents <- st_read(dsn = \"data/chap03/IncidentsSecuritePublique.shp\", quiet=TRUE)\n## Changement de projection\nArrondissements <- st_transform(Arrondissements, crs = 3798) \nIncidents <- st_transform(Incidents, crs = 3798)\n## Extaction des méfaits\nMefaits <- subset(Incidents, DESCRIPTIO == \"Méfait\")\n# Méfaits par année\nM2019 <- subset(Mefaits, ANNEE==2019)\nM2020 <- subset(Mefaits, ANNEE==2020)\nM2021 <- subset(Mefaits, ANNEE==2021)\nM2022 <- subset(Mefaits, ANNEE==2022)\n# Coordonnées géographiques\nxy.2019 <- st_coordinates(M2019)\nxy.2020 <- st_coordinates(M2020)\nxy.2021 <- st_coordinates(M2021)\nxy.2022 <- st_coordinates(M2022)\n```\n:::\n\n\n\n\n\n\nLes méfaits par année sont présentés à la @fig-CarteMefaits.\n\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![Localisation des méfaits par année, ville de Sherbrooke, 2021](03-MethodesRepartitionPonctuelle_files/figure-pdf/fig-CarteMefaits-1.pdf){#fig-CarteMefaits fig-align='center' width=85%}\n:::\n:::\n\n\n\n\n\n\n**Centre moyen**\n\nAvec la fonction `mean`, nous pouvons calculer les valeurs moyennes sur les coordonnées *X* et *Y*, puis créer un objet `sf` avec les centres moyens.\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## Récupération de la projection cartographique dans une variable\nProjCarto <- st_crs(Mefaits)\n## Calcul du centre moyen pour une année (2019)\nprint(c(mean(xy.2019[,1]), mean(xy.2019[,2])))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 649990.3 157059.3\n```\n\n\n:::\n\n```{.r .cell-code}\n## Calcul pour toutes les années\n# vecteur pour les moyennes des X\nX.moy <- c(mean(xy.2019[,1]), mean(xy.2020[,1]), mean(xy.2021[,1]), mean(xy.2022[,1]))\n# Vecteur pour les moyennes des Y\nY.moy <- c(mean(xy.2019[,2]), mean(xy.2020[,2]), mean(xy.2021[,2]), mean(xy.2022[,2]))\n# Enregistrement dans un objet sf\nCentreMoyen <- data.frame(Annee = c(\"2019\", \"2020\", \"2021\", \"2022\"),\n                          X = X.moy, \n                          Y = Y.moy,\n                          CMx = X.moy,  \n                          CMy = Y.moy)\nCentreMoyen <- st_as_sf(CentreMoyen, coords = c(\"X\", \"Y\"), crs = ProjCarto)\n# Affichage des résultats\nprint(CentreMoyen)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nSimple feature collection with 4 features and 3 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 649696 ymin: 157059.3 xmax: 650663.7 ymax: 157544.8\nProjected CRS: NAD83 / MTQ Lambert\n  Annee      CMx      CMy                  geometry\n1  2019 649990.3 157059.3 POINT (649990.3 157059.3)\n2  2020 649696.0 157544.8   POINT (649696 157544.8)\n3  2021 650663.7 157214.8 POINT (650663.7 157214.8)\n4  2022 650442.5 157237.0   POINT (650442.5 157237)\n```\n\n\n:::\n:::\n\n\n\n\n\n\n**Point central**\n\nLe code ci-dessous illustre comment identifier le point central, qui fait partie du jeu de données, pour l'année 2019.\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## Calcul de la matrice de distances entre les points de l'année 2019\nDistMatrice2019 <- as.matrix(dist(xy.2019, method = \"euclidean\", diag = TRUE, upper = TRUE))\n## Somme de chaque ligne de la matrice, soit la somme des distances à tous les autres points\nM2019$DistATous <- rowSums(DistMatrice2019)\n## Sélection du point avec plus petite distance à tous les autres\nPointCentral2019 <- subset(M2019, M2019$DistATous==min(M2019$DistATous))\n```\n:::\n\n\n\n\n\n\n**Distance standard sur les coordonnées *X* et *Y* et distance standard combinée**\n\nLe code ci-dessous permet de calculer les trois distances standards.\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## Calcul de la distance standard pour une année (2019)\n# Distance standard sur les coordonnées X et Y\nc(sqrt(mean((xy.2019[,1] - mean(xy.2019[,1]))^2)),\n  sqrt(mean((xy.2019[,2] - mean(xy.2019[,2]))^2)))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 3732.173 2593.207\n```\n\n\n:::\n\n```{.r .cell-code}\n# Distance standard\nsqrt(mean((xy.2019[,1] - mean(xy.2019[,1]))**2 + \n            (xy.2019[,2] - mean(xy.2019[,2]))**2))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 4544.649\n```\n\n\n:::\n\n```{.r .cell-code}\n## Calcul pour toutes les années et enregistrement des centres moyens dans de nouveaux champs\nCentreMoyen$DS.X <- c(sqrt(mean((xy.2019[,1] - mean(xy.2019[,1]))^2)),\n                      sqrt(mean((xy.2020[,1] - mean(xy.2020[,1]))^2)),\n                      sqrt(mean((xy.2021[,1] - mean(xy.2021[,1]))^2)),\n                      sqrt(mean((xy.2022[,1] - mean(xy.2022[,1]))^2)))\n\nCentreMoyen$DS.Y <- c(sqrt(mean((xy.2019[,2] - mean(xy.2019[,2]))^2)),\n                       sqrt(mean((xy.2020[,2] - mean(xy.2020[,2]))^2)),\n                       sqrt(mean((xy.2021[,2] - mean(xy.2021[,2]))^2)),\n                       sqrt(mean((xy.2022[,2] - mean(xy.2022[,2]))^2)))\n\nCentreMoyen$DS <- c(sqrt(mean((xy.2019[,1] - mean(xy.2019[,1]))**2 +\n                              (xy.2019[,2] - mean(xy.2019[,2]))**2)),\n                    sqrt(mean((xy.2020[,1] - mean(xy.2020[,1]))**2 +\n                              (xy.2020[,2] - mean(xy.2020[,2]))**2)),+\n                    sqrt(mean((xy.2021[,1] - mean(xy.2021[,1]))**2 +\n                              (xy.2021[,2] - mean(xy.2021[,2]))**2)),+\n                    sqrt(mean((xy.2022[,1] - mean(xy.2022[,1]))**2 +\n                              (xy.2022[,2] - mean(xy.2022[,2]))**2)))\n## Visualisation des résultats\nhead(CentreMoyen)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nSimple feature collection with 4 features and 6 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 649696 ymin: 157059.3 xmax: 650663.7 ymax: 157544.8\nProjected CRS: NAD83 / MTQ Lambert\n  Annee      CMx      CMy                  geometry     DS.X     DS.Y       DS\n1  2019 649990.3 157059.3 POINT (649990.3 157059.3) 3732.173 2593.207 4544.649\n2  2020 649696.0 157544.8   POINT (649696 157544.8) 4134.913 2393.048 4777.466\n3  2021 650663.7 157214.8 POINT (650663.7 157214.8) 3374.821 2294.171 4080.764\n4  2022 650442.5 157237.0   POINT (650442.5 157237) 3601.208 2170.215 4204.585\n```\n\n\n:::\n:::\n\n\n\n\n\n\n**Représentations graphiques de la dispersion**\n\nUne fois que la couche `sf` des centres moyens avec les trois champs pour la distance standard est créée, il suffit de tracer un rectangle et un cercle de distance standard.\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## Enveloppe convexe\nsf.Enveloppes <- st_sf(data.frame(Id=c(\"2019\", \"2020\", \"2021\", \"2022\")),\n                    geometry = c(st_convex_hull(st_union(M2019)),\n                                 st_convex_hull(st_union(M2020)),\n                                 st_convex_hull(st_union(M2021)),\n                                 st_convex_hull(st_union(M2022))))\n## Rectangle avec les distances standards sur les coordonnées X et Y\n#' Fonction pour tracer le rectangle\n#' @param MoyX coordonnées X du centre moyen.\n#' @param MoyY coordonnées Y du centre moyen.\n#' @param SDx distance standard sur les coordonnées X.\n#' @param SDy distance standard sur les coordonnées Y.\n#' @param crs projection cartographique.\nCreationRec <- function(MoyX, MoyY, SDx, SDy, ProjCarto){\n  pt1 = c(MoyX - SDx, MoyY - SDy)\n  pt2 = c(MoyX - SDx, MoyY + SDy)\n  pt3 = c(MoyX + SDx, MoyY + SDy)\n  pt4 = c(MoyX + SDx, MoyY - SDy)\n  Rectangle = st_polygon(list(rbind(pt1, pt2, pt3, pt4, pt1)))\n  Rectangle = st_sfc(Rectangle)\n  st_crs(Rectangle) = ProjCarto\n  return(Rectangle)\n}\nMoyX <- CentreMoyen$CMx\nMoyY <- CentreMoyen$CMy\nSDx <- CentreMoyen$DS.X\nSDy <- CentreMoyen$DS.Y\nsf.Rectangles <- st_sf(data.frame(Id=c(\"2019\", \"2020\", \"2021\", \"2022\")),\n                    geometry = c(CreationRec(MoyX[1], MoyY[1], SDx[1], SDy[1], ProjCarto),\n                                 CreationRec(MoyX[2], MoyY[2], SDx[2], SDy[2], ProjCarto),\n                                 CreationRec(MoyX[3], MoyY[3], SDx[3], SDy[3], ProjCarto),\n                                 CreationRec(MoyX[4], MoyY[4], SDx[4], SDy[4], ProjCarto)))\n## Cercle de distance standard avec la fonction st_buffer\nsf.CercleDS <- st_buffer(CentreMoyen, dist = CentreMoyen$DS)\n```\n:::\n\n\n\n\n\n\nLe calcul de l'ellipse est un peu plus complexe. Par conséquent, nous avons écrit deux fonctions :\n\n-   `CreateEllipse` qui construit une ellipse à partir d'une couche `sf` de points.\n\n-   `CreateEllipse_gp` qui construit des ellipses à partir d'une couche `sf` de points en fonction d'une colonne indiquant différents groupes de points (ici, les différentes années).\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## Appel des deux fonctions dans le fichier ellipses.R\nsource(\"code_complementaire/ellipses.R\")\n## Création d'une ellipse pour une année \nsf.Ellipse2019 <- CreateEllipse(M2019)\n## Création de plusieurs ellipses regroupées selon les différentes années\nsf.Ellipse <- CreateEllipse_gp(points = Mefaits, group = \"ANNEE\")\nhead(sf.Ellipse)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nSimple feature collection with 4 features and 12 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 643833.8 ymin: 153377.3 xmax: 655559 ymax: 160937.9\nProjected CRS: NAD83 / MTQ Lambert\n       CMx      CMy   Sigmax   Sigmay       Lx        Ly     Aire    Theta\n1 649990.3 157059.3 3055.157 5683.790 6110.315 11367.580 54553357 64.60944\n2 649696.0 157544.8 3154.712 5994.647 6309.423 11989.294 59411858 75.81068\n3 650663.7 157214.8 3128.891 4869.299 6257.783  9738.598 47863757 76.14675\n4 650442.5 157237.0 2540.594 5406.184 5081.187 10812.368 43149511 68.52718\n  ThetaCorr  Major  Minor                       geometry ANNEE\n1  64.60944 SigmaY SigmaX POLYGON ((655125.1 159496.4...  2019\n2  75.81068 SigmaY SigmaX POLYGON ((655507.7 159014.3...  2020\n3  76.14675 SigmaY SigmaX POLYGON ((655391.4 158380.7...  2021\n4  68.52718 SigmaY SigmaX POLYGON ((655473.5 159216, ...  2022\n```\n\n\n:::\n:::\n\n\n\n\n\n\nLes quatre représentations de la dispersion sont présentées à la @fig-RepresentationDispersion : 1) enveloppe convexe (gris), 2) cercle de distance standard (bleu), 3) rectangle de distance standard sur les X et Y (noir) et 4) ellipse de distance standard (rouge).\n\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![Représentations de la dispersion des méfaits pour les quatre années](03-MethodesRepartitionPonctuelle_files/figure-pdf/fig-RepresentationDispersion-1.pdf){#fig-RepresentationDispersion fig-align='center' width=85%}\n:::\n:::\n\n\n\n\n\n\n#### Calcul de mesures pondérées {#sec-03132}\n\nPour illustrer le calcul des mesures pondérées, nous utilisons des données sur les effectifs des premier et dernier déciles de revenu après impôt des familles économiques pour les secteurs de recensement de la ville de Sherbrooke en 2021 (@fig-CartesDecilesPremierDernier).\n\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![Déciles extrêmes de revenu après impôt des familles économiques](03-MethodesRepartitionPonctuelle_files/figure-pdf/fig-CartesDecilesPremierDernier-1.pdf){#fig-CartesDecilesPremierDernier fig-align='center' width=85%}\n:::\n:::\n\n\n\n\n\n\nLe code suivant permet d'importer et de structurer les données, puis de calculer les différentes mesures (centre moyen pondéré et distance standard pondérée).\n\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n## Importation et structuration des données\ndfdecile <- read.csv(\"data/chap03/DataDecilesSR.csv\", header = TRUE, sep = \",\")\ndfdecile$SRIDU <- substr(dfdecile$SRIDU, 1, 10)\nSR <- st_read(dsn = \"data/chap03/Recen2021Sherbrooke.gpkg\",\n              layer = \"DR_SherbSRDonnees2021\", quiet=TRUE)\nSR <- merge(SR[,c(\"SRIDU\")], dfdecile, by = \"SRIDU\")\nProjCarto <- st_crs(SR)\n## Coordonnées géographiques des secteurs de recensement\nxy <- st_coordinates(st_point_on_surface(SR))\n## Pondérations pour les deux déciles\nwd1  <- SR$D1\nwd10 <- SR$D10\n## Sommes des pondérations\nswd1  <- sum(wd1)\nswd10 <- sum(wd10)\n## Calcul du centre pondéré\nXmoyD1  <- sum(xy[,1]*wd1) / swd1\nXmoyD10 <- sum(xy[,1]*wd10) / swd10\nYmoyD1  <- sum(xy[,2]*wd1) / swd1\nYmoyD10 <- sum(xy[,2]*wd10) / swd10\nCentreMoyenPond <- data.frame(Decile = c(\"Premier\", \"Dernier\"),\n                          X = c(XmoyD1, XmoyD10), \n                          Y = c(YmoyD1, YmoyD10),\n                          CMwx = c(XmoyD1, XmoyD10),  \n                          CMwy = c(YmoyD1, YmoyD10))\nCentreMoyenPond <- st_as_sf(CentreMoyenPond, coords = c(\"X\", \"Y\"), crs = ProjCarto)\n## Calcul de la distance standard pondérée\nsdD1  <- sqrt((sum(wd1*(xy[,1]- XmoyD1)^2) / swd1) + (sum(wd1*(xy[,2]- YmoyD1)^2) / swd1))\nsdD10 <- sqrt((sum(wd10*(xy[,1]- XmoyD10)^2) / swd1) + (sum(wd10*(xy[,2]- YmoyD10)^2) / swd10))\n## Zones tampons avec la distance standard pondérée\nCentreMoyenPond$SDw <- c(sdD1, sdD10)\nsf.CercleDSW <- st_buffer(CentreMoyenPond, dist = CentreMoyenPond$SDw)\n\n## Calcul de l'ellipse pondérée pour le premier décile\nSR.points <- st_point_on_surface(SR)\nellipse.D1 <- CreateEllipse(SR.points, w = SR.points$D1)\nellipse.D10 <- CreateEllipse(SR.points, w = SR.points$D10)\n\n# Carte 1 : premier décile\nCarte1 = tm_shape(SR)+\n              tm_polygons(col=\"whitesmoke\", border.col = \"grey30\", lwd = 1)+\n          tm_shape(CentreMoyenPond[1,])+\n              tm_dots(size = .5, col=\"black\")+\n          tm_shape(sf.CercleDSW[1,])+\n              tm_borders(col=\"blue\", lwd = 2)+      \n          tm_shape(ellipse.D1)+\n              tm_borders(col=\"red\", lwd = 2)+    \n  tm_layout(main.title = \"A. Premier décile (le plus pauvre)\",\n            main.title.size = .9, frame = FALSE)\n# Carte 2 : dernier décile\nCarte2 = tm_shape(SR)+\n              tm_polygons(col=\"whitesmoke\", border.col = \"grey30\", lwd = 1)+\n          tm_shape(CentreMoyenPond[2,])+\n              tm_dots(size = .5, col=\"black\")+\n          tm_shape(sf.CercleDSW[2,])+\n              tm_borders(col=\"red\", lwd = 2)+         \n          tm_shape(ellipse.D10)+\n              tm_borders(col=\"blue\", lwd = 2)+    \n tm_layout(main.title = \"B. Dernier décile (le plus riche)\",\n            main.title.size = .9, frame = FALSE)+\ntm_credits(\"Source : recensement de 2021, Statistique Canada\\nAuteur : Jéremy Lécartemplace.\", \n             position = c(\"right\", \"bottom\"), size = 0.7, align = \"right\")\n# Combinaison des deux cartes\ntmap_arrange(Carte1, Carte2, ncol = 2, nrow = 1)\n```\n\n::: {.cell-output-display}\n![Cercles de distance standard et ellipses pondérés](03-MethodesRepartitionPonctuelle_files/figure-pdf/fig-MesuresPonderees-1.pdf){#fig-MesuresPonderees fig-align='center' fig-pos='H' width=85%}\n:::\n:::\n\n\n\n\n\n\n## Forme d'un semis de points {#sec-033}\n\nÉtudier la forme d'un semis de points, c'est vouloir décrire l'arrangement spatial et l'espacement des points dans une région donnée. Autrement dit, l'objectif est de répondre à la question suivante : comment se répartissent les points dans une région donnée? Nous distinguons habituellement trois types de distribution spatiale d'un semis de points (@fig-FormeSemisDePoints3Types) :\n\n1.  **Distribution dispersée** quand les points du semis sont régulièrement espacés.\n2.  **Distribution aléatoire** quand la distribution des points n'est nullement guidée par des considérations géographiques. Autrement dit, chaque point du semis a la même probabilité d'être situé dans n'importe quelle partie de la zone d'étude.\n3.  **Distribution concentrée** quand il existe des regroupements de points dans une ou plusieurs parties de la région d'étude. Par exemple, les musées et les théâtres sont habituellement concentrés dans les parties centrales des métropoles.\n\n![Trois types de distribution spatiale d'un semis de points](images/Chap03/FigureTroisTypesDistributions.png){#fig-FormeSemisDePoints3Types width=\"65%\" fig-align=\"center\"}\n\n::: bloc_attention\n::: bloc_attention-header\n::: bloc_attention-icon\n:::\n\n**Deux grandes familles pour décrire la forme d'un semis de points**\n:::\n\n::: bloc_attention-body\n1.  Celles basées sur la distance (l'indice du plus proche voisin, fonctions *K* et *L* de Ripley) ([section @sec-0331]).\n2.  Celles basées sur la densité (méthode des quadrats avec différents tests statistiques) ([section @sec-0332]).\n:::\n:::\n\n### Méthode du plus proche voisin {#sec-0331}\n\nLe principe de base de cette méthode est fort simple et se décompose en quatre étapes :\n\n1.  Mesurer, pour chaque point du semis, la distance le séparant du point le plus proche, puis calculer la distance moyenne du point le plus proche (@eq-PlusProcheVoisinRobs).\n\n2.  Calculer la moyenne attendue du point le plus proche pour une dispersion aléatoire (@eq-PlusProcheVoisinR).\n\n3.  Calculer l'indice du plus proche voisin, soit le ratio entre la distance observée et la distance aléatoire (@eq-PlusProcheVoisinRExp). L'indice *R* s'interprète alors comme suit :\n\n    -   Si *R* est égal à 1, la dispersion du semis de points est aléatoire.\n    -   Si *R* est inférieur à 1, la distribution du semis de points tend vers la concentration (avec une concentration absolue quand *R* = 0; tous les points ont les mêmes coordonnées géographiques).\n    -   Si *R* est supérieur à 1, la distribution du semis de points tend vers la dispersion.\n\n4.  Calculer les valeurs de *Z* et de *p* pour déterminer si la valeur de *R* obtenue est significative (@eq-PlusProcheVoisinZ).\n\n$$\nR_{o}= \\frac{\\sum_{i=1}^n d_i}{n}\n$$ {#eq-PlusProcheVoisinRobs}\n\n$$\nR_{a}= \\frac{1}{2 \\sqrt{(n/S)}}\n$$ {#eq-PlusProcheVoisinRExp}\n\n$$\nR = \\frac{R_{o}}{R_{a}}\n$$ {#eq-PlusProcheVoisinR}\n\n$$\nZ = \\frac{R_o-R_a}{SE} \\text{, } SE = \\frac{0.26136}{\\sqrt{(n^2/S)}} \\text{ avec :}\n$$ {#eq-PlusProcheVoisinZ}\n\n-   $n$, nombre de points.\n-   $d_i$, distance séparant le point *i* de son voisin le plus proche.\n-   $S$, superficie de l'espace d'étude.\n\nLe code ci-dessous permet de mettre en œuvre la méthode du plus proche voisin pour les méfaits pour les quatre années.\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(spatstat)\nlibrary(ggplot2)\n## Indice du plus proche voisin : R observé (équation 3.20)\n# le paramètre k indique le nombre de plus proches voisins\nRobs2019 <- mean(nndist(st_coordinates(M2019), k=1))\nRobs2020 <- mean(nndist(st_coordinates(M2020), k=1))\nRobs2021 <- mean(nndist(st_coordinates(M2021), k=1))\nRobs2022 <- mean(nndist(st_coordinates(M2022), k=1))\n## Indice du plus proche voisin : R attendu (distribution aléatoire) (équation 3.21)\n# Attention, il faut spéficier S, la superficie de l'espace d'étude\nArrondissements <-  st_read(dsn = \"data/chap03/Arrondissements.shp\", quiet=TRUE)\nArrondissements <- st_transform(Arrondissements, crs = 3798) \nS <- as.numeric(st_area(st_union(Arrondissements)))\n# Nombre de points par année\nN2019 <- nrow(M2019)\nN2020 <- nrow(M2020)\nN2021 <- nrow(M2021)\nN2022 <- nrow(M2022)\n# Calcul de Ra\nRa2019 <- 1 / (2 * sqrt(N2019 / S))\nRa2020 <- 1 / (2 * sqrt(N2020 / S))\nRa2021 <- 1 / (2 * sqrt(N2021 / S))\nRa2022 <- 1 / (2 * sqrt(N2022 / S))\n## Calculons le R\n# Création d'un DataFrame\nIndicePPV <- data.frame(id = c(\"2019\", \"2020\", \"2021\", \"2022\"),\n                               points = c(N2019, N2020, N2021, N2022),\n                               Superficie = c(S, S, S, S),\n                               Robs = c(Robs2019, Robs2020, Robs2021, Robs2022),\n                               Rattendu = c(Ra2019, Ra2020, Ra2021, Ra2022))\n# Calcul du R (équation 3.22)\nIndicePPV$R <- IndicePPV$Robs / IndicePPV$Rattendu\n# Calcul du Z (équation 3.23)\nIndicePPV$SE <- 0.26136 / sqrt(IndicePPV$points^2 / IndicePPV$Superficie)\nIndicePPV$Z <- (IndicePPV$Robs - IndicePPV$Rattendu) / IndicePPV$SE\nIndicePPV$P <- round(2*pnorm(q=abs(IndicePPV$Z), lower.tail=FALSE),3)\nprint(IndicePPV)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n    id points Superficie     Robs Rattendu         R       SE         Z P\n1 2019    251  366358191 251.5498 604.0684 0.4164260 19.93051 -17.68739 0\n2 2020    383  366358191 183.9866 489.0166 0.3762380 13.06151 -23.35335 0\n3 2021    344  366358191 227.1881 515.9929 0.4402931 14.54232 -19.85961 0\n4 2022    220  366358191 251.3347 645.2256 0.3895299 22.73890 -17.32234 0\n```\n\n\n:::\n:::\n\n\n\n\n\n\n**Interprétation des résultats**\n\nAnalysons les différentes colonnes du @tbl-TableauMPPV :\n\n-   **points (n) :** il y a respectivement 251, 383, 344 et 220 méfaits pour les années 2019 à 2022.\n\n-   ***R*** **observé :** en moyenne, un méfait est distant de 252, 184, 227 et 251 mètres du méfait le plus proche pour les quatre années.\n\n-   ***R*** **attendu :** pour une distribution aléatoire, un méfait devrait être distant du méfait le plus proche de 604, 489, 516, et 645 mètres.\n\n-   **Indice du plus proche voisin :** toutes les valeurs sont inférieures à 1, indiquant des distributions spatiales concentrées. La concentration est la plus forte pour l'année 2020 (R = 0,376).\n\n-   **valeur de *p* :** toutes les valeurs sont égales à 0, signalant que les résultats sont significatifs.\n\n\n\n\n\n\n::: {#tbl-TableauMPPV .cell tbl-cap='Résultats de la méthode du plus proche voisin pour les méfaits par année'}\n::: {.cell-output-display}\n\n\n| Année | points (n) | *R* observé | *R* attendu | Indice plus proche voisin | Erreur standard |    Z    | *p* |\n|:-----:|:----------:|:-----------:|:-----------:|:-------------------------:|:---------------:|:-------:|:---:|\n| 2019  |    251     |     252     |     604     |           0,416           |     19,931      | -17,687 |  0  |\n| 2020  |    383     |     184     |     489     |           0,376           |     13,062      | -23,353 |  0  |\n| 2021  |    344     |     227     |     516     |           0,440           |     14,542      | -19,860 |  0  |\n| 2022  |    220     |     251     |     645     |           0,390           |     22,739      | -17,322 |  0  |\n\n\n:::\n:::\n\n\n\n\n\n\nNotez qu'il est possible aussi de construire un graphique pour le *R* observé avec plusieurs voisins, tel que réalisé avec le code ci-dessous avec *k* = 1 à 50 (@fig-IndicePlusProchVoisin150).\n\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# k = 1 à 50\nRobs2019N1_50 <- apply(nndist(st_coordinates(M2019), k=1:50), 2, FUN=mean)\nRobs2020N1_50 <- apply(nndist(st_coordinates(M2020), k=1:50), 2, FUN=mean)\nRobs2021N1_50 <- apply(nndist(st_coordinates(M2021), k=1:50), 2, FUN=mean)\nRobs2022N1_50 <- apply(nndist(st_coordinates(M2022), k=1:50), 2, FUN=mean)\n# Enregistrement dans des dataFrames\nRobs2019N1_50 <- data.frame(An=\"2019\", Voisins=1:length(Robs2019N1_50), Robs=Robs2019N1_50)\nRobs2020N1_50 <- data.frame(An=\"2020\", Voisins=1:length(Robs2020N1_50), Robs=Robs2020N1_50)\nRobs2021N1_50 <- data.frame(An=\"2021\", Voisins=1:length(Robs2021N1_50), Robs=Robs2021N1_50)\nRobs2022N1_50 <- data.frame(An=\"2022\", Voisins=1:length(Robs2022N1_50), Robs=Robs2022N1_50)\n# Combinaison des dataFrames en un seul\nRobsN1_50 <- rbind(Robs2019N1_50, Robs2020N1_50, Robs2021N1_50, Robs2022N1_50)\n# Création du graphique\nggplot(RobsN1_50)+\n geom_point(aes(x = Voisins, y = Robs, color = An))+\n geom_line(aes(x = Voisins, y = Robs, color = An))+\nlabs(x = \"Nombre de voisins\",\n     y = \"Robs - Distance en mètres\",\n     color = \"Année\")\n```\n\n::: {.cell-output-display}\n![Distance au plus proche voisin de 1 à 50](03-MethodesRepartitionPonctuelle_files/figure-pdf/fig-IndicePlusProchVoisin150-1.pdf){#fig-IndicePlusProchVoisin150 fig-align='center' fig-pos='H' width=85%}\n:::\n:::\n\n\n\n\n\n\n### Méthode des quadrats {#sec-0332}\n\n#### Principe de base {#sec-03231}\n\nLe principe de base de la méthode des quadrats peut être décomposé en trois étapes :\n\n1.  Superposer à la région d'étude comprenant le semis de points un ensemble de **quadrats** (habituellement une grille régulière formée d'un ensemble de carrés).\n2.  Compter le nombre de points compris dans chacun des quadrats. De la sorte, certains quadrats ne comprennent aucun point tandis que d'autres en contiennent un, deux, trois, etc. Nous obtenons ainsi un tableau des fréquences.\n3.  Réaliser des tests statistiques à partir des fréquences observées et théoriques pour qualifier la distribution du semis de points (test de Kolmogorov-Smirnov, test du khi-deux ou méthode Monte-Carlo).\n\n#### Forme, distribution et taille des quadrats {#sec-03252}\n\nIl est possible de paramétrer les quadrats selon leur forme, leur distribution et leur taille. Habituellement, la forme retenue pour les quadrats est le carré, mais d'autres formes géométriques peuvent être utilisées comme l'hexagone et plus rarement, le cercle. La distribution des quadrats peut aussi être soit régulière, soit aléatoire (@fig-FormeQuadrats). Notez que dans le cas d'un cercle, le maillage ne peut être qu'irrégulier puisque certains points risqueraient de ne pas être contenus dans un cercle pour un maillage régulier.\n\n![Formes et distributions de quadrats](images/Chap03/FormesQuadrats.png){#fig-FormeQuadrats width=\"75%\" fig-align=\"center\"}\n\nBien entendu, les résultats varient selon la taille des quadrats. Par exemple, dans le cas d'une distribution spatiale concentrée d'un semis de points, diminuer la taille des quadrats risque d'augmenter la perception de la dispersion. Certains auteurs proposent alors une formule pour déterminer la superficie optimale du quadrat [@wong2005statistical; @mitchel2005esri] :\n\n$$\nS_q = \\frac{2S}{n}\n$$ {#eq-TailleQuadrat}\n\n$$\nl_q = \\sqrt{S_q} \\text{ et } r_q = \\sqrt{\\frac{S_q}{\\pi}} \\text{ et } l_a = \\sqrt{ \\frac{2S_q}{3 \\sqrt{3}}} \\text{ avec :} \n$$ {#eq-TailleQuadratLongueur}\n\n-   $S_q$, superficie du quadrat.\n-   $n$, nombre de points dans le semis.\n-   $l_q$, longueur du côté si la forme du quadrat est un carré.\n-   $r_q$, longueur du rayon si la forme du quadrat est un cercle.\n-   $l_a$, longueur du côté d'un hexagone régulier.\n\n#### Tests statistiques {#sec-03253}\n\n**Construction du tableau de fréquences observées et théoriques**\n\nUne fois les quadrats créés, nous devons compter le nombre de points compris dans chacun d'eux. Une distribution spatiale concentrée à l'extrême se traduit par la localisation de tous les points du semis d'un seul quadrat, tandis que pour une distribution dispersée maximale se traduit par le fait que tous les quadrats contiennent le même nombre de points. Par la suite, nous construisons un tableau de fréquences.\n\nPrenons deux situations à la @fig-FormeQuadratsExemple :\n\n1.  **A. Une distribution dispersée**, puisque les points sont présents dans la plupart des quadrats.\n2.  **B. Une distribution concentrée**, puisque les points sont localisés dans quelques quadrats.\n\nNotez que pour les deux situations, nous avons 42 points ($n$) et 36 quadrats ($k$), soit une moyenne de 1,167 point par quadrat ($\\lambda = n / k = 42 / 36 = 1,167$). Détaillons les différentes colonnes du tableau de fréquences observées et théoriques :\n\n-   **Fréquences observées (**$f_o$) : pour la situation A, nous avons 16 quadrats qui ne comprennent aucun point, 4 quadrats avec 1 point, 10 quadrats avec 2 points et finalement 6 quadrats avec 3 points. À l'inverse, pour la situation B, 27 quadrats sur les 36 ne comprennent aucun point, suggérant ainsi une concentration plus forte!\n\n-   **Proportions observées :** simplement les fréquences observées divisées par le nombre total de quadrats (par exemple, $16 / 36 = 0,444$ pour A).\n\n-   **Proportions théoriques :** à partir de la loi de probabilité de Poisson (@eq-QuadratPoisson), il est possible de calculer les proportions théoriques que nous devrions avoir si les points étaient distribués aléatoirement. Pas de panique avec la lecture de la formule, nous verrons qu'il existe une fonction pour la calculer facilement dans R. Nous calculons aussi les **proportions théoriques cumulées**.\n\n-   **Fréquences théoriques :** les fréquences théoriques sont simplement les proportions théoriques multipliées par le nombre de quadrats (par exemple, $\\text{0,311} \\times 36 = \\text{11,196}$).\n\n$$\np(x = k )= \\frac{\\lambda^k e^{-\\lambda}}{x!}\\text{ avec :}\n$$ {#eq-QuadratPoisson}\n\n$\\lambda \\text{ (lambda)} = n / k$, soit le nombre moyen de points ($n$) par quadrat ($k$); $x$, le nombre de points dans le quadrat (0, 1, 2, etc.); $!x$, la factorielle d'un nombre (par exemple, $!3 = 1 \\times 2 \\times 3 = 6$); $e$, la constante de l'Euler, soit $exp(1) = \\text{2,718282}$.\n\nÀ partir de ce tableau des fréquences observées et théoriques, nous pouvons calculer les tests de Kolmogorov-Smirnov et du khi-deux.\n\n![Illustrations des tests statistiques sur les quadrats](images/Chap03/FormesQuadratsExemple.png){#fig-FormeQuadratsExemple width=\"100%\" fig-align=\"center\"}\n\n**Test statistique de Kolmogorov-Smirnov**\n\nCe test se décompose en six étapes :\n\n1.  Formuler l'hypothèse nulle stipulant que les fréquences observées et théoriques ne sont pas statistiquement différentes ($H_0$).\n\n2.  Choisir un seuil de signification pour valider ou réfuter l'hypothèse nulle (par exemple, $\\alpha = \\text{0,05}$).\n\n3.  Calculer la différence absolue entre les proportions cumulées observées et théoriques.\n\n4.  Calculer la statistique $D$, soit la plus forte valeur des différences absolues entre les fréquences cumulées observées et théoriques (@eq-DValeurKS).\n\n5.  Calculer la valeur critique pour une distribution aléatoire avec un seuil de signification $\\alpha$ (@eq-DValeurKSCritique).\n\n6.  Comparer les valeurs de $D$ et de $D_{\\alpha = 0.05}$ :\n\n    -   Si $D = D_{\\alpha \\text{ = 0,05}}$, la distribution est aléatoire.\n\n    -   Si $D < D_{\\alpha \\text{ = 0,05}}$, la distribution est dispersée.\n\n    -   Si $D > D_{\\alpha \\text{ = 0,05}}$, la distribution est concentrée. Plus la valeur de $D$ est élevée, plus la distribution spatiale du semis de points est concentrée.\n\n$$\nD = \\text{max}\\lvert poi_{cumulé} - pti_{cumulé} \\rvert\n$$ {#eq-DValeurKS}\n\n$$\nD_{\\alpha = \\text{0,05}}= \\frac{\\text{1,36}}{\\sqrt{m}}\\text{ avec }\n$$ {#eq-DValeurKSCritique}\n\n$m$ étant le nombre total de quadrats; $poi_{cumulé}$ et $pti_{cumulé}$, les proportions cumulées observées et théoriques.\n\nAppliquons cette démarche du test de Kolmogorov-Smirnov aux deux distributions de la @fig-FormeQuadratsExemple :\n\n-   $D_{\\alpha = \\text{0,05}}= \\frac{\\text{1,36}}{\\sqrt{36}}=\\text{0,210}$\n-   pour la situation A, $D = \\text{0,133}$, donc $D < D_{\\alpha = \\text{0,05}}$, alors la distribution est significativement dispersée.\n-   pour la situation B, $D = \\text{0,439}$, donc $D > D_{\\alpha = \\text{0,05}}$, alors la distribution est significativement concentrée.\n\n**Test statistique du khi-deux**\n\nCe test se décompose en quatre étapes :\n\n1.  Formuler l'hypothèse nulle stipulant que la distribution des fréquences observées dans les quadrats suit une distribution de Poisson ($H_0$).\n\n2.  Calculer le khi-deux (@eq-KhiDeux).\n\n3.  Comparer la valeur du khi-deux obtenue avec celle du khi-deux théorique ($\\chi^2_{\\alpha,dl}$) avec $k-1$ degrés de liberté ($dl$) et un seuil de signification $\\alpha$ (0,05 par exemple).\n\n4.  Si $\\chi^2 > \\chi^2_{\\alpha,dl}$, alors l'hypothèse nulle est rejetée.\n\n$$\n\\chi^2 = \\sum_{i=1}^k \\frac{(O_i - E_i)^2}{E_i}\\text{ avec }\n$$ {#eq-KhiDeux}\n\n$O_i$ et $E_i$ étant respectivement les fréquences observée et attendue pour $i$ (quadrat avec 0 point, 1, 2, etc.).\n\nPour les deux situations, le khi-deux calculé est supérieur au khi-deux théorique avec un seuil $\\alpha$ de 0,001 et 35 degrés de liberté (paramètre `df` dans la fonction `qchisq` pour *degrees of freedom*). Par conséquent, les deux distributions ne sont pas aléatoires.\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nround(qchisq(p=0.95,  df=35, lower.tail = TRUE),3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 49.802\n```\n\n\n:::\n\n```{.r .cell-code}\nround(qchisq(p=0.99,  df=35, lower.tail = TRUE),3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 57.342\n```\n\n\n:::\n\n```{.r .cell-code}\nround(qchisq(p=0.999,  df=35, lower.tail = TRUE),3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 66.619\n```\n\n\n:::\n:::\n\n\n\n\n\n\n::: bloc_attention\n::: bloc_attention-header\n::: bloc_attention-icon\n:::\n\n**Loi de Poisson : pas de panique!**\n:::\n\n::: bloc_attention-body\nVous n'êtes pas familier avec la loi de probabilité de Poisson et le test du khi-deux, retenez simplement la démarche générale, nous utilisons des fonctions qui vont vous faciliter la vie dans R!\n:::\n:::\n\n#### Mise en œuvre dans R {#sec-03254}\n\nLe code suivant permet de déterminer la superficie optimale des quadrats en fonction du nombre de points (méfaits pour l'année 2020) et de la superficie de l'espace d'étude.\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(spatstat)\n## Taille des quadrats\n# Nombre de points\nnpoints <- nrow(M2020)\n# Superficie de l'espace d'étude\nS <- as.numeric(st_area(st_union(Arrondissements)))\n# Superficie du quadrat (équation 3.24)\nSq <- (2*S) / npoints\n# Longueur du carré et du côté de l'hexagone régulier (équation 3.25)\nlq <- sqrt(Sq)\nla <- sqrt((2*Sq) / (3*sqrt(3)))\n# Trouver la longueur du côté du carré dans lequel est compris l'hexagone \ncellsizeHex <- 2 * sqrt(Sq/((3*sqrt(3)/2))) * sqrt(3)/2\ncat(\"Nombre de points =\", npoints,\n    \"\\nSuperficie (éq. 3.24) =\", Sq,\n    \"\\nLongueur du côté du carré (éq. 3.25) =\", lq, \n    \"\\nLongueur du côté du l'hexagone (éq. 3.25) =\", la,\n    \"\\nLongueur du côté du carré dans lequel est compris l'hexagone =\", cellsizeHex, \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nNombre de points = 383 \nSuperficie (éq. 3.24) = 1913098 \nLongueur du côté du carré (éq. 3.25) = 1383.148 \nLongueur du côté du l'hexagone (éq. 3.25) = 858.1093 \nLongueur du côté du carré dans lequel est compris l'hexagone = 1486.289 \n```\n\n\n:::\n:::\n\n\n\n\n\n\nNous pouvons ensuite créer deux couches avec des quadrats carrés et hexagonaux avec la fonction `st_make_grid` du *package* `sf`. Repérez le paramètre `square` dans la fonction `st_make_grid` : écrivez `square = TRUE` pour obtenir des carrés et `square = FALSE` pour des hexagones réguliers.\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## Création des quadrats\n#Géométrie pour l'espace d'étude\nEspaceEtude <- st_geometry(st_union(Arrondissements))\n# Création des carrés\nCarres.sf <- st_make_grid(EspaceEtude, \n                     lq,  \n                     crs = st_crs(Arrondissements),\n                     what  = \"polygons\",\n                     square = TRUE)\n# Création des hexagones\nHexagones.sf <- st_make_grid(EspaceEtude, \n                     cellsizeHex,  \n                     crs = st_crs(Arrondissements),\n                     what  = \"polygons\",\n                     square = FALSE)\nCarres.sf <- st_sf(idCarre = 1:length(lengths(Carres.sf)), Carres.sf)\nHexagones.sf <- st_sf(idHex = 1:length(lengths(Hexagones.sf)), Hexagones.sf)\ncat(\"Superficie (éq. 3.24) =\", Sq,\n    \"\\nVérifier la superficie des carrés et des hexagones\",\n    \"\\nSuperficie des carrés =\", as.numeric(st_area(Carres.sf[1,])),\n    \"\\nSuperficie des hexagones =\", as.numeric(st_area(Hexagones.sf[1,])), \n    \"Les superficies sont bien égales!\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nSuperficie (éq. 3.24) = 1913098 \nVérifier la superficie des carrés et des hexagones \nSuperficie des carrés = 1913098 \nSuperficie des hexagones = 1913098 Les superficies sont bien égales!\n```\n\n\n:::\n\n```{.r .cell-code}\n## Visualisation\ntmap_mode(\"plot\")\n tm_shape(Hexagones.sf)+tm_borders(col=\"black\")+\n tm_shape(Carres.sf)+tm_borders(col=\"red\")+\n tm_shape(Arrondissements)+tm_borders(col=\"blue\", lwd=3)+\n   tm_shape(M2020)+tm_dots(col=\"green\", size=0.15)+\n   tm_layout(frame = FALSE)\n```\n\n::: {.cell-output-display}\n![](03-MethodesRepartitionPonctuelle_files/figure-pdf/unnamed-chunk-20-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n\n\n\n\nLa figure ci-dessus permet de constater que certains carrés et hexagones n'intersectent pas l'espace d'étude. Par conséquent, nous les supprimons puis calculons le nombre de points par carré et par hexagone.\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## Suppression des carrés qui n'intersectent pas les quatre arrondissements\nRequeteSpatiale <- st_intersects(Carres.sf, \n                                 st_union(Arrondissements), sparse = FALSE)\nCarres.sf$Intersect <- RequeteSpatiale[, 1]\nCarres.sf <- Carres.sf[Carres.sf$Intersect == TRUE, ]\n## Suppression des hexagones qui n'intersectent pas les quatre arrondissements\nRequeteSpatiale <- st_intersects(Hexagones.sf, \n                                 st_union(Arrondissements), sparse = FALSE)\nHexagones.sf$Intersect <- RequeteSpatiale[, 1]\nHexagones.sf <- Hexagones.sf[Hexagones.sf$Intersect == TRUE, ]\n## Jointure spatiale : compter le nombre de méfaits de 2020 dans les carrés et les hexagones\nCarres.sf$Mefaits2020    = lengths(st_intersects(Carres.sf, M2020))\nHexagones.sf$Mefaits2020 = lengths(st_intersects(Hexagones.sf, M2020))\n## Tableau de fréquences\ntable(Carres.sf$Mefaits2020)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n  0   1   2   3   4   5   6   7   8  10  11  13  21  38  41  64 \n172  25   6   3   8   1   3   4   3   2   3   1   1   1   1   1 \n```\n\n\n:::\n\n```{.r .cell-code}\ntable(Hexagones.sf$Mefaits2020)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n  0   1   2   3   4   5   6   7   8   9  15  17  19  20  40  48 \n173  23   5   5   3   5   6   1   3   1   2   1   1   1   1   2 \n```\n\n\n:::\n:::\n\n\n\n\n\n\nVisualisons les résultats à la @fig-fig2PointsCarresHex. Il y a clairement une tendance à la concentration puisque de nombreux quadrats ne contiennent aucun point.\n\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n## Visualisation\ntmap_mode(\"plot\")\nCarte1 <-\n  tm_shape(subset(Carres.sf, Mefaits2020 == 0))+\n     tm_polygons(col=\"gray90\", border.col = \"white\", lwd = 1)+\n   tm_shape(subset(Carres.sf, Mefaits2020!= 0))+\n      tm_polygons(col=\"Mefaits2020\", style=\"cont\", title=\"Nombre\", \n                  border.col = \"white\", lwd = 1)+\n   tm_shape(Arrondissements)+tm_borders(col=\"black\", lwd=2)+\n   tm_layout(frame = FALSE)\nCarte2 <-\n  tm_shape(subset(Hexagones.sf, Mefaits2020 == 0))+\n     tm_polygons(col=\"gray90\", border.col = \"white\", lwd = 1)+\n   tm_shape(subset(Hexagones.sf, Mefaits2020!= 0))+\n      tm_polygons(col=\"Mefaits2020\", style=\"cont\", title=\"Nombre\",\n                  border.col = \"white\", lwd = 1)+\n   tm_shape(Arrondissements)+tm_borders(col=\"black\", lwd=2)+\n   tm_layout(frame = FALSE) \ntmap_arrange(Carte1, Carte2)\n```\n\n::: {.cell-output-display}\n![Nombre de méfaits dans les deux géométries de quadrats](03-MethodesRepartitionPonctuelle_files/figure-pdf/fig-fig2PointsCarresHex-1.pdf){#fig-fig2PointsCarresHex fig-align='center' fig-pos='H' width=85%}\n:::\n:::\n\n\n\n\n\n\nNous pouvons maintenant construire le tableau de fréquences et mettre en œuvre les différents tests statistiques. Le code ci-dessous génère le tableau de fréquences et applique **le test de Kolmogorov-Smirnov**.\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## Construction du tableau de fréquences\nTabFreq <- as.data.frame(table(Carres.sf$Mefaits2020))\nnames(TabFreq) <- c(\"Npoints\", \"Fo\")\nTabFreq$Npoints <- as.numeric(as.character(TabFreq$Npoints))\n# Calcul pour les fréquences observées (fo)\nTabFreq$Fo.pro <- TabFreq$Fo / sum(TabFreq$Fo)\nTabFreq$Fo.proCum <- cumsum(TabFreq$Fo.pro)\n# Calcul pour les fréquences théoriques\nnpoints <- sum(TabFreq$Npoints*TabFreq$Fo)\nnquadrats <- sum(TabFreq$Fo)\nLambda <- npoints / nquadrats\nTabFreq$Ft.pro <- dpois(TabFreq$Npoints, lambda = Lambda)\nTabFreq$Ft.proCum <- ppois(TabFreq$Npoints, lambda = Lambda, lower.tail = TRUE)\nTabFreq$Ft <- TabFreq$Ft.pro * TabFreq$Npoints\n# Différences absolues entre les fréquences observées et théoriques cumulées\nTabFreq$Difffoft <- abs(TabFreq$Fo.proCum - TabFreq$Ft.proCum)\n#calcul de D et Da\nD <- max(TabFreq$Difffoft)\nDa <- 1.36 / sqrt(nquadrats) # avec p à 0,05\n## Diagnostic\nif (D>Da){\n  cat(\"D =\",round(D,3),\" et Da =\", round(Da,3),\n      \"\\nD > Da avec p =0,05, alors la distribution tend vers la concentration.\")\n}else{\n  cat(\"D =\",round(D,3),\" et Da =\", round(Da,3),\n      \"\\nD < Da avec p =0,05, alors la distribution tend vers la dispersion.\")\n}\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nD = 0.536  et Da = 0.089 \nD > Da avec p =0,05, alors la distribution tend vers la concentration.\n```\n\n\n:::\n:::\n\n\n\n\n\n\nLe *package* `spatstat` permet de réaliser différents tests avec la fonction `quadrat.test`. Pour ce faire, il faut préalablement convertir les données dans les formats utilisés par ce *package* (`ppp`, `owin` et `tess`).\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## Conversion des points au format ppp\nM2020.ppp <- ppp(x = st_coordinates(M2020)[,1],\n                 y = st_coordinates(M2020)[,2],\n                 window = as.owin(Arrondissements), \n                 check = T)\n## Conversion des quadrats carrés ou hexagonaux en objet owin\nquadrats <- as(st_geometry(Carres.sf), \"Spatial\") \nFenetresC <- lapply(quadrats@polygons,function(x){\n  coords <- x@Polygons[[1]]@coords\n  coords<-coords[nrow(coords):1,]\n  owin(poly = coords)})\n\nquadrats <- as(st_geometry(Hexagones.sf), \"Spatial\") \nFenetresH <- lapply(quadrats@polygons,function(x){\n  coords <- x@Polygons[[1]]@coords\n  coords<-coords[nrow(coords):1,]\n  owin(poly = coords)})\n## Ces fenêtres sont ensuite converties en un objet tess (tesselation)\nTessalationC <- as.tess(FenetresC)\nTessalationH <- as.tess(FenetresH)\n```\n:::\n\n\n\n\n\n\nNous pouvons calculer différents tests avec la fonction `quadrat.test`. Dans un premier temps, nous vérifions si **la distribution est dispersée** avec la méthode Monte-Carlo et 999 permutations (`alternative =\"regular\"`). Que ce soit avec les quadrats carrés ou hexagonaux, la valeur de *p* est égale à 1. Cela signifie que nous sommes 100 % certains que la distribution n'est pas dispersée.\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## Réalisation des différents tests du khi-deux\n# test pour une distribution dispersée (Carrés)\ncat(\"Test pour une distribution dispersée avec les quadrats carrés\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nTest pour une distribution dispersée avec les quadrats carrés\n```\n\n\n:::\n\n```{.r .cell-code}\nquadrat.test(M2020.ppp, tess = TessalationC,\n             method = \"MonteCarlo\", nsim = 999,\n             alternative =\"regular\")  # dispersée\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tConditional Monte Carlo test of CSR using quadrat counts\n\tTest statistic: Pearson X2 statistic\n\ndata:  M2020.ppp\nX2 = 5212.2, p-value = 1\nalternative hypothesis: regular\n\nQuadrats: 235 tiles (irregular windows)\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Test pour une distribution dispersée avec les quadrats hexagonaux\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nTest pour une distribution dispersée avec les quadrats hexagonaux\n```\n\n\n:::\n\n```{.r .cell-code}\nquadrat.test(M2020.ppp, tess = TessalationH,\n             method = \"MonteCarlo\", nsim = 999,\n             alternative =\"regular\")  # dispersée\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tConditional Monte Carlo test of CSR using quadrat counts\n\tTest statistic: Pearson X2 statistic\n\ndata:  M2020.ppp\nX2 = 4792.3, p-value = 1\nalternative hypothesis: regular\n\nQuadrats: 233 tiles (irregular windows)\n```\n\n\n:::\n:::\n\n\n\n\n\n\nDans un second temps, nous vérifions si **la distribution est concentrée**, toujours avec la méthode Monte-Carlo et 999 permutations (`alternative =\"clustered\"`). Que ce soit avec les quadrats carrés ou hexagonaux, la valeur de *p* est égale à 0,001. Cela signifie qu'il y a moins de 1 % de chances que la distribution concentrée soit due au hasard.\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# test pour une distribution concentrée\ncat(\"Test pour une distribution concentrée avec les quadrats carrés\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nTest pour une distribution concentrée avec les quadrats carrés\n```\n\n\n:::\n\n```{.r .cell-code}\nquadrat.test(M2020.ppp, tess = TessalationC,\n             method = \"MonteCarlo\", nsim = 999,\n             alternative =\"clustered\") # concentrée\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tConditional Monte Carlo test of CSR using quadrat counts\n\tTest statistic: Pearson X2 statistic\n\ndata:  M2020.ppp\nX2 = 5212.2, p-value = 0.001\nalternative hypothesis: clustered\n\nQuadrats: 235 tiles (irregular windows)\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Test pour une distribution concentrée avec les quadrats hexagonaux\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nTest pour une distribution concentrée avec les quadrats hexagonaux\n```\n\n\n:::\n\n```{.r .cell-code}\nquadrat.test(M2020.ppp, tess = TessalationH,\n             method = \"MonteCarlo\", nsim = 999,\n             alternative =\"clustered\") # concentrée\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tConditional Monte Carlo test of CSR using quadrat counts\n\tTest statistic: Pearson X2 statistic\n\ndata:  M2020.ppp\nX2 = 4792.3, p-value = 0.001\nalternative hypothesis: clustered\n\nQuadrats: 233 tiles (irregular windows)\n```\n\n\n:::\n:::\n\n\n\n\n\n\n## Cartographie de la densité des points {#sec-034}\n\nPour repérer les concentrations d'un semis de points dans une région, il faut cartographier la densité des points dans une maille soit irrégulière, soit régulière.\n\n### Cartographie de la densité dans une maille irrégulière {#sec-0341}\n\nUne maille irrégulière est habituellement un découpage administratif comme les municipalités régionales de comté (MRC) du Québec ou les arrondissements d'une ville.\n\nÀ la @fig-figDensiteIrreguliere, nous avons compté le nombre de méfaits par secteur de recensement pour l'année 2021, puis calculé la densité, soit le nombre de méfaits pour 1000 habitants. Les cercles proportionnels permettent ainsi de repérer les secteurs comprenant le plus de méfaits. Comme la population totale varie d'un SR à l'autre, il est préférable de cartographier la densité, soit le nombre de méfaits pour 1000 habitants. Notez que pour d'autres jeux de données, il serait plus judicieux d'utiliser la superficie comme dénominateur pour calculer la densité (par exemple, le nombre d'arbres au kilomètre carré ou à l'hectare).\n\nEn quelques lignes de code, il est très facile de calculer et de cartographier la densité dans un maillage irrégulier.\n\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n## Secteurs de recensement (SR) de la ville de Sherbrooke en 2021\nSR <- st_read(dsn = \"data/chap03/Recen2021Sherbrooke.gpkg\",\n              layer = \"DR_SherbSRDonnees2021\", quiet=TRUE)\n## Sélection des méfaits pour l'année 2021\nIncidents <- st_read(dsn = \"data/chap03/IncidentsSecuritePublique.shp\", quiet=TRUE)\nM2021 <- subset(Incidents, DESCRIPTIO == \"Méfait\" & ANNEE==2021)\n## Nous nous assurons que les deux couches ont la même projection cartographique\nSR <- st_transform(SR, st_crs(M2021))\n## Calcul du nombre d'incidents par SR \nSR$Mefaits2021 <- lengths(st_intersects(SR, M2021))\n## Calcul du nombre de méfaits pour 1000 habitants\nSR$DensiteM21Hab <- SR$Mefaits2021 / (SR$SRpop_2021 / 1000)\n## Cartographie\ntm_shape(SR)+\n  tm_polygons(col=\"Mefaits2021\", style=\"pretty\", \n              title=\"Nombre pour 1000 habitants\",\n\t\t\t  legend.format = list(text.separator = \"à\"),\n              border.col = \"black\", lwd = 1)+\n  tm_bubbles(size = \"DensiteM21Hab\", border.col = \"black\", alpha = .5,\n                     col = \"aquamarine3\", title.size = \"Nombre\", scale = 1.5)+ \n  tm_layout(frame = FALSE)+tm_scale_bar(text.size = .5, c(0, 5, 10))\n```\n\n::: {.cell-output-display}\n![Densité des méfaits par secteur de recensement, ville de Sherbrooke, 2021](03-MethodesRepartitionPonctuelle_files/figure-pdf/fig-figDensiteIrreguliere-1.pdf){#fig-figDensiteIrreguliere fig-align='center' fig-pos='H' width=85%}\n:::\n:::\n\n\n\n\n\n\n### Cartographie de la densité dans une maille régulière {#sec-0342}\n\n#### Notion de processus spatial {#sec-03421}\n\nLorsque nous analysons des évènements ayant eu lieu dans un espace donné, nous pouvons considérer que ces évènements résultent d'un processus spatial que nous ne pouvons pas observer. Ce processus spatial est caractérisé par des points chauds (endroits où des évènements se produisent souvent) et des points froids (endroits où des évènements se produisent rarement). Si nous collectons suffisamment d'évènements (observations), alors leur densité devrait nous renseigner sur ce processus spatial. Puisqu'une image vaut mille mots, examinons un exemple d'un processus spatial à la @fig-figExempleProcSpat.\n\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![Exemple d'un processus spatial](03-MethodesRepartitionPonctuelle_files/figure-pdf/fig-figExempleProcSpat-1.pdf){#fig-figExempleProcSpat fig-align='center' width=85%}\n:::\n:::\n\n\n\n\n\n\nImaginons que ce processus spatial représente le niveau de risque de se faire attaquer par un écureuil dans un parc urbain délimité ici par les limites de la figure. Dans la réalité, nous ne pouvons pas mesurer directement ce phénomène, mais nous disposons d'un registre des attaques d'écureuils qui ont été enregistrées et spatialisées (@fig-figExempleProcSpat2). Bien entendu, ces données sont fictives! Dans un langage plus technique, il est dit que **les évènements sont des réalisations du processus spatial**.\n\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\npts <- rpoint(1500, dens1)\nplot(pts, main = \"Attaques d'écureuils enregistrées\")\n```\n\n::: {.cell-output-display}\n![Réalisation du processus spatial](03-MethodesRepartitionPonctuelle_files/figure-pdf/fig-figExempleProcSpat2-1.pdf){#fig-figExempleProcSpat2 fig-align='center' fig-pos='H' width=85%}\n:::\n:::\n\n\n\n\n\n\nPuisque nous disposons d'un grand nombre d'observations, nous pouvons reconstruire le processus spatial qui produit les évènements en appliquant la méthode d'analyse de densité dans une maille régulière (@fig-figExempleProcSpat3).\n\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![Reconstruction du processus spatial](03-MethodesRepartitionPonctuelle_files/figure-pdf/fig-figExempleProcSpat3-1.pdf){#fig-figExempleProcSpat3 fig-align='center' width=85%}\n:::\n:::\n\n\n\n\n\n\nLa qualité d'estimation du processus initial dépend ainsi directement du nombre d'évènements dont nous disposons (@fig-figExempleProcSpat3).\n\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![Reconstruction du processus spatial](03-MethodesRepartitionPonctuelle_files/figure-pdf/fig-figExempleProcSpat4-1.pdf){#fig-figExempleProcSpat4 fig-align='center' width=85%}\n:::\n:::\n\n\n\n\n\n\nUne fois que nous sommes en mesure de recréer le processus spatial, nous pouvons en apprendre plus sur le phénomène et ses causes. Par exemple, est-ce que les secteurs du parc avec les plus grandes concentrations d'accidents sont aussi ceux dans lesquels sont localisés des jeux pour enfants?\n\n#### Description de la méthode KDE {#sec-03422}\n\nLe principe de base d'une cartographie de la densité dans une maille régulière -- appelée aussi carte de chaleur ou estimation de la densité par noyau (*kernel density estimation* -- KDE, en anglais) -- est relativement simple et se décompose en trois étapes :\n\n1.  Juxtaposer une grille de cellules sur l'espace d'étude, soit les pixels d'une image de *n* mètres de côté (par exemple, 50 mètres).\n2.  Pour chaque pixel, juxtaposer une zone de recherche de *n* mètres de rayon (1000 mètres par exemple) et calculer le nombre de points présents dans cette zone de recherche.\n3.  Calculer la densité à partir d'une fonction simple (appelée habituellement fonction uniforme) ou d'une fonction de densité (*kernel*). Pour une fonction simple, nous divisons simplement le nombre de points présents dans la zone de recherche par la superficie de la zone, soit $\\pi r^2$; cette approche est toutefois peu recommandée puisqu'elle accorde la même pondération à chaque point situé de la zone d'influence! En utilisant une fonction de densité (*kernel*) (@eq-KernelDensity), nous accordons une pondération à chacun des points compris dans la zone de recherche : plus le point est proche du centre de la cellule, plus son poids est important dans l'estimation de la densité.\n\n$$\n\\lambda(s) = \\sum_{i=1}^n \\frac{1}{\\pi r^2} k\\biggl(\\frac{d_{si}}{r}\\biggl)\\text{ avec }\n$$ {#eq-KernelDensity}\n\n-   $\\lambda(s)$, estimation de la densité à la localisation $s$.\n-   $r$, rayon de la zone de recherche.\n-   $d_{is}$, distance entre la localisation $s$ et le point $i$.\n-   $k$, fonction *kernel* définissant la pondération à accorder au ratio $\\frac{d_{si}}{r}$ quand $0 < d_{si} \\leq r$. Si $d_{si} > r$, alors $k(d_{si}/r) = 0$.\n\nIl existe différentes fonctions *kernel* pour obtenir les pondérations des points. Telle qu'illustrée à la @fig-IllustationKernel, l'idée générale est que plus la distance entre la localisation et le point augmente ($d_{si}$), plus la pondération $k(d_{si}/r)$ de l'équation @eq-KernelDensity est faible.\n\n![Principe de la fonction *kernel* pour définir les pondérations des points voisins dans la zone d'influence](images/Chap03/IlustratorKernel.png){#fig-IllustationKernel width=\"100%\" fig-align=\"center\"}\n\n::: bloc_astuce\n::: bloc_astuce-header\n::: bloc_astuce-icon\n:::\n\n**Les différentes fonctions *kernel* d'estimation de la densité**\n:::\n\n::: bloc_astuce-body\nPour une description des différentes fonctions *kernel*, [consultez le lien suivant](https://fr.wikipedia.org/wiki/Noyau_(statistiques)). Notez que l'outil *Carte de chaleur (estimation par noyau)* de QGIS inclut plusieurs fonctions *kernel* alors que l'outil *Kernel Density* d'ArcGIS Pro utilise uniquement la fonction quadratique. Finalement, la fonction `density.ppp` du *package* `spatstat` intègre quatre fonctions.\n\n**Influence de la forme du noyau (fonction *kernel*)**\n\nExcepté la fonction uniforme, la plupart des auteurs s'entendent sur le fait que le choix de fonctions *kernel* a relativement peu d'influence sur le résultat final comparativement au choix du rayon d'influence.\n\n\n\n\n\n\n::: {#tbl-TableauFonctionsKernel .cell tbl-cap='Fonctions *kernel* disponibles selon différents logiciels'}\n::: {.cell-output-display}\n\n\n|      Fonction| QGis | ArcGIS Pro | CrimeStat | R (density.ppp) |\n|-------------:|:----:|:----------:|:---------:|:---------------:|\n|    Gaussienne|      |            |     X     |        X        |\n|  Triangulaire|  X   |            |     X     |                 |\n|   Quadratique|  X   |     X      |     X     |        X        |\n|      Uniforme|  X   |            |     X     |        X        |\n|       Cubique|  X   |            |           |                 |\n|  Epanechnikov|  X   |            |           |        X        |\n| Exponentielle|      |            |     X     |                 |\n\n\n:::\n:::\n\n\n\n\n\n:::\n:::\n\n#### Mise en œuvre de la KDE dans R {#sec-03423}\n\nPour calculer la densité dans une maille régulière (KDE), vous pouvez utiliser deux *packages* :\n\n1.  `SpatialKDE`, un *package* proposé récemment qui reprend le code de l'outil *Carte de chaleur (estimation par noyau)* de QGIS [@SpatialKDEPackage]. Vous obtiendrez donc les mêmes fonctionnalités et résultats qu'avec QGIS. Pour un exemple d'utilisation, consultez [cette vignette](https://cran.r-project.org/web/packages/SpatialKDE/vignettes/SpatialKDE.html).\n2.  `spatstat`, soit le *package* le plus complet pour réaliser des analyses de répartition ponctuelle [@spatstatPackage; @baddeley2015spatial]. Par conséquent, nous privilégions son utilisation dans les exemples ci-dessous.\n\nAfin d'expliquer comment réaliser une KDE dans R, nous utilisons les accidents survenus dans l'arrondissement des Nations de la ville de Sherbrooke. Notez que nous retenons uniquement cet arrondissement et non l'ensemble de la ville afin d'accélérer les temps de calculs.\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(sf)\nlibrary(spatstat)\nlibrary(tmap)\nlibrary(terra)\n## Importation des données \nArrondissements <-  st_read(dsn = \"data/chap03/Arrondissements.shp\", quiet = TRUE)\nArrondissements <-  st_transform(Arrondissements, crs = 3798) \nincidents <- st_read(dsn = \"data/chap03/IncidentsSecuritePublique.shp\", quiet = TRUE)\nIncidents <- st_transform(Incidents, crs = 3798)\n## Couche pour les accidents\nAccidents <- subset(Incidents, Incidents$DESCRIPTIO %in% \n                      c(\"Accident avec blessés\", \"Accident mortel\"))\n## Pour accélérer les calculs, nous retenons uniquement l'arrondissement des Nations\n# Couche pour l'arrondissement des Nations\nArrDesNations <- subset(Arrondissements, NOM == \"Arrondissement des Nations\")\n# Sélection des accidents localisés dans l'arrondissement des Nations\nRequeteSpatiale <- st_intersects(Accidents, ArrDesNations, sparse = FALSE)\nAccidents$Nations <- RequeteSpatiale[, 1]\nAccNations <- subset(Accidents, Accidents$Nations == TRUE)\n# Une couche par année\nAccNations2019 <- subset(AccNations, AccNations$AN == 2019)\nAccNations2020 <- subset(AccNations, AccNations$AN == 2020)\nAccNations2021 <- subset(AccNations, AccNations$AN == 2021)\nAccNations2022 <- subset(AccNations, AccNations$AN == 2022)\n```\n:::\n\n\n\n\n\n\nNous convertissons les points dans le format `ppp` utilisé par le *package* `spatstat`.\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## Conversion des données sf dans le format de spatstat\n# la fonction as.owin est utilisée pour définir la fenêtre de travail\nfenetre <- as.owin(ArrDesNations)\n## Conversion des points au format ppp pour les différentes années\n# 2019 \nAccN2019.ppp <- ppp(x = st_coordinates(AccNations2019)[,1],\n                    y = st_coordinates(AccNations2019)[,2],\n                    window = fenetre, check = T)\n# 2020 \nAccN2020.ppp <- ppp(x = st_coordinates(AccNations2020)[,1],\n                    y = st_coordinates(AccNations2020)[,2],\n                    window = fenetre, check = T) \n# 2021 \nAccN2021.ppp <- ppp(x = st_coordinates(AccNations2021)[,1],\n                    y = st_coordinates(AccNations2021)[,2],\n                    window = fenetre, check = T)\n# 2022\nAccN2022.ppp <- ppp(x = st_coordinates(AccNations2022)[,1],\n                    y = st_coordinates(AccNations2022)[,2],\n                    window = fenetre, check = T)\n```\n:::\n\n\n\n\n\n\nPuis, il faut définir la taille des pixels et le rayon d'influence (*bandwidth* en anglais) :\n\n-   Plus la taille des pixels est réduite, plus la taille de l'image résultante est importante et les calculs longs à réaliser.\n\n-   Le choix du rayon est aussi délicat. Avec un rayon trop petit, les résultats sont trop détaillés avec des valeurs très faibles. À l'inverse, un rayon trop grand a comme effet de lisser les résultats et de masquer des disparités locales.\n\n::: bloc_astuce\n::: bloc_astuce-header\n::: bloc_astuce-icon\n:::\n\n**Ratio entre la taille du pixel et la taille du rayon d'influence**\n:::\n\n::: bloc_astuce-body\nAssurez-vous que la taille du pixel soit bien inférieure (au moins dix fois plus petite) à celle du rayon d'influence afin d'obtenir des résultats précis. À notre connaissance, il n'existe pas de règle pour optimiser la valeur ratio entre la taille du pixel et la taille du rayon d'influence.\n:::\n:::\n\nPlusieurs algorithmes permettant de sélectionner la valeur optimale du rayon d'influence sont implémentés dans le *package* `spatstat` avec les fonctions `bw.diggle`, `bw.ppl`, `bw.scott` et `bw.CvL`. À la lecture des résultats ci-dessous, la valeur du rayon proposée par l'algorithme de Diggle semble bien trop petite et celle du critère de Cronie et van Lieshout bien trop grande. Le rayon optimal est certainement compris entre 700 et 750 mètres. Par conséquent, nous retenons une taille de pixel de 50 mètres et la valeur du rayon optimisée par la fonction `bw.ppl`.\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncat(\"\\nDiggle :\", bw.diggle(AccN2020.ppp),\n    \"\\nMaximum de vraissemblance :\", bw.ppl(AccN2020.ppp),\n    \"\\nCritère de Scott 1 :\", bw.scott(AccN2020.ppp)[1],\n    \"\\nCritère  de Scott 2 :\", bw.scott(AccN2020.ppp)[2],\n    \"\\nCritère de Cronie et van Lieshout :\", bw.CvL(AccN2020.ppp))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nDiggle : 124.196 \nMaximum de vraissemblance : 494.5408 \nCritère de Scott 1 : 971.3489 \nCritère  de Scott 2 : 514.2688 \nCritère de Cronie et van Lieshout : 1644.489\n```\n\n\n:::\n\n```{.r .cell-code}\n## Taille des pixels et du rayon en mètres\npixel_m <- 50\nRayonOpt <- bw.ppl(AccN2020.ppp)\n```\n:::\n\n\n\n\n\n\n##### Comparaison des fonctions *kernel* {#sec-034221}\n\nLe paramètre `kernel` de la fonction `density.ppp` permet de sélectionner l'une des quatre fonctions *kernel* (`gaussian`, `quartic`, `epanechnikov` et `disc`). Pour la dernière, le même poids est attribué aux points compris dans le rayon d'influence; elle correspond ainsi à un *kernel* uniforme ou simple. Excepté ce dernier *kernel*, la @fig-CartoQuatreKernels démontre que les résultats sont très semblables d'un *kernel* à l'autre.\n\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n## Calcul de la KDE avec différentes fonctions kernel\n# kernel gaussien\nkdeG <- density.ppp(AccN2020.ppp, sigma=RayonOpt, eps=pixel_m, kernel=\"gaussian\")\n# kernel quadratique\nkdeQ <- density.ppp(AccN2020.ppp, sigma=RayonOpt, eps=pixel_m, kernel=\"quartic\")\n# kernel Epanechnikov\nkdeE <- density.ppp(AccN2020.ppp, sigma=RayonOpt, eps=pixel_m, kernel=\"epanechnikov\")\n# kernel disc (uniforme ou simple)\n# le même poids est accordé à chaque point dans le rayon\nkdeD <- density.ppp(AccN2020.ppp, sigma=RayonOpt, eps=pixel_m, kernel=\"disc\")\n## Conversion en raster \n# étant donné que les valeurs sont exprimées en nombre de points par m2,\n# nous les multiplions par 1 000 000 pour obtenir une densité au km2.\nRkdeG <- terra::rast(kdeG)*1000000\nRkdeQ <- terra::rast(kdeQ)*1000000\nRkdeE <- terra::rast(kdeE)*1000000\nRkdeD <- terra::rast(kdeD)*1000000\n## Projection cartographique\ncrs(RkdeG) <- \"epsg:3798\"\ncrs(RkdeQ) <- \"epsg:3798\" \ncrs(RkdeE) <- \"epsg:3798\" \ncrs(RkdeD) <- \"epsg:3798\"\n## Visualisation des résultats\ntmap_mode(\"plot\")\nCarte1 <-\n  tm_shape(RkdeG) + tm_raster(style = \"cont\", palette=\"Reds\", title = \"Gaussien\")+\n  tm_shape(AccNations2020) + tm_dots(col = \"black\", size = 0.01)+\n  tm_shape(ArrDesNations) + tm_borders(col = \"black\", lwd = 2)+\n  tm_layout(frame = FALSE)\nCarte2 <-\n  tm_shape(RkdeQ) + tm_raster(style = \"cont\", palette=\"Reds\", title = \"Quadratique\")+\n  tm_shape(AccNations2020) + tm_dots(col = \"black\", size = 0.01)+\n  tm_shape(ArrDesNations) + tm_borders(col = \"black\", lwd = 2)+\n  tm_layout(frame = FALSE)\nCarte3 <-\n  tm_shape(RkdeE) + tm_raster(style = \"cont\", palette=\"Reds\", title = \"Epanechnikov\")+\n  tm_shape(AccNations2020) + tm_dots(col = \"black\", size = 0.01)+\n  tm_shape(ArrDesNations) + tm_borders(col = \"black\", lwd = 2)+\n  tm_layout(frame = FALSE)\nCarte4 <-\n  tm_shape(RkdeD) + tm_raster(style = \"cont\", palette=\"Reds\", title = \"Uniforme\")+\n  tm_shape(AccNations2020) + tm_dots(col = \"black\", size = 0.01)+\n  tm_shape(ArrDesNations) + tm_borders(col = \"black\", lwd = 2)+\n  tm_scale_bar(breaks  = c(0, 1, 2))+tm_layout(frame = FALSE)\ntmap_arrange(Carte1, Carte2, Carte3, Carte4,\n             ncol = 2, nrow = 2)\n```\n\n::: {.cell-output-display}\n![Comparaison des résultats de la KDE pour différents kernels](03-MethodesRepartitionPonctuelle_files/figure-pdf/fig-CartoQuatreKernels-1.pdf){#fig-CartoQuatreKernels fig-align='center' fig-pos='H' width=85%}\n:::\n:::\n\n\n\n\n\n\n##### Évaluation de l'impact du rayon d'influence {#sec-034222}\n\nLe code R permet de réaliser des KDE avec des rayons de 250, 500, 750 et 1000 mètres. La @fig-CartoQuatreKernels démontre bien que plus le rayon est grand, plus la carte est lissée.\n\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nkdeQ250  <- density.ppp(AccN2020.ppp, sigma=250,  eps=50, kernel=\"quartic\")\nkdeQ500  <- density.ppp(AccN2020.ppp, sigma=500,  eps=50, kernel=\"quartic\")\nkdeQ750  <- density.ppp(AccN2020.ppp, sigma=750,  eps=50, kernel=\"quartic\")\nkdeQ1000 <- density.ppp(AccN2020.ppp, sigma=1000, eps=50, kernel=\"quartic\")\nRkdeQ250  <- terra::rast(kdeQ250)*1000000\nRkdeQ500  <- terra::rast(kdeQ500)*1000000\nRkdeQ750  <- terra::rast(kdeQ750)*1000000\nRkdeQ1000 <- terra::rast(kdeQ1000)*1000000\ncrs(RkdeQ250) <- \"epsg:3798\"\ncrs(RkdeQ500) <- \"epsg:3798\" \ncrs(RkdeQ750) <- \"epsg:3798\" \ncrs(RkdeQ1000) <- \"epsg:3798\"\n\n## Visualisation des résultats\ntmap_mode(\"plot\")\nCarte1 <-\n  tm_shape(RkdeQ250) + tm_raster(style = \"cont\", palette=\"Reds\", title = \"r = 250 m\")+\n  tm_shape(AccNations2020) + tm_dots(col = \"black\", size = 0.01)+\n  tm_shape(ArrDesNations) + tm_borders(col = \"black\", lwd = 2)+\n  tm_layout(frame = FALSE)\nCarte2 <-\n  tm_shape(RkdeQ500) + tm_raster(style = \"cont\", palette=\"Reds\", title = \"r = 500 m\")+\n  tm_shape(AccNations2020) + tm_dots(col = \"black\", size = 0.01)+\n  tm_shape(ArrDesNations) + tm_borders(col = \"black\", lwd = 2)+\n  tm_layout(frame = FALSE)\nCarte3 <-\n  tm_shape(RkdeQ750) + tm_raster(style = \"cont\", palette=\"Reds\", title = \"r = 750 m\")+\n  tm_shape(AccNations2020) + tm_dots(col = \"black\", size = 0.01)+\n  tm_shape(ArrDesNations) + tm_borders(col = \"black\", lwd = 3)+\n  tm_layout(frame = FALSE)\nCarte4 <-\n  tm_shape(RkdeQ1000) + tm_raster(style = \"cont\", palette=\"Reds\", title = \"r = 1000 m\")+\n  tm_shape(AccNations2020) + tm_dots(col = \"black\", size = 0.01)+\n  tm_shape(ArrDesNations) + tm_borders(col = \"black\", lwd = 2)+\n  tm_scale_bar(breaks  = c(0, 1, 2))+\n  tm_layout(frame = FALSE)\ntmap_arrange(Carte1, Carte2, Carte3, Carte4,\n             ncol = 2, nrow = 2)\n```\n\n::: {.cell-output-display}\n![Comparaison des résultats de la KDE selon le rayon d'influence](03-MethodesRepartitionPonctuelle_files/figure-pdf/fig-CartoDistKernels-1.pdf){#fig-CartoDistKernels fig-align='center' fig-pos='H' width=85%}\n:::\n:::\n\n\n\n\n\n\n##### Comparaison entre différentes années {#sec-034223}\n\nBien entendu, pour un même jeu de données, il est possible de représenter la densité pour différentes années (@fig-CartoTemporelleKernels).\n\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nkde2019 <- density.ppp(AccN2019.ppp, sigma=500, eps=50, kernel=\"quartic\")\nkde2020 <- density.ppp(AccN2020.ppp, sigma=500, eps=50, kernel=\"quartic\")\nkde2021 <- density.ppp(AccN2021.ppp, sigma=500, eps=50, kernel=\"quartic\")\nkde2022 <- density.ppp(AccN2022.ppp, sigma=500, eps=50, kernel=\"quartic\")\nRkde2019 <- terra::rast(kde2019)*1000000\nRkde2020 <- terra::rast(kde2020)*1000000\nRkde2021 <- terra::rast(kde2020)*1000000\nRkde2022 <- terra::rast(kde2021)*1000000\ncrs(Rkde2019) <- \"epsg:3798\"\ncrs(Rkde2020) <- \"epsg:3798\" \ncrs(Rkde2021) <- \"epsg:3798\" \ncrs(Rkde2022) <- \"epsg:3798\"\n\nCarte1 <-\n  tm_shape(Rkde2019) + tm_raster(style = \"cont\", palette=\"Reds\", title = \"2019\")+\n  tm_shape(AccNations2019) + tm_dots(col = \"black\", size = 0.01)+\n  tm_shape(ArrDesNations) + tm_borders(col = \"black\", lwd = 2)+\n  tm_layout(frame = FALSE)\nCarte2 <-\n  tm_shape(Rkde2020) + tm_raster(style = \"cont\", palette=\"Reds\", title = \"2021\")+\n  tm_shape(AccNations2020) + tm_dots(col = \"black\", size = 0.01)+\n  tm_shape(ArrDesNations) + tm_borders(col = \"black\", lwd = 2)+\n  tm_layout(frame = FALSE)\nCarte3 <-\n  tm_shape(Rkde2021) + tm_raster(style = \"cont\", palette=\"Reds\", title = \"2022\")+\n  tm_shape(AccNations2021) + tm_dots(col = \"black\", size = 0.01)+\n  tm_shape(ArrDesNations) + tm_borders(col = \"black\", lwd = 2)+\n  tm_layout(frame = FALSE)\nCarte4 <-\n  tm_shape(Rkde2022) + tm_raster(style = \"cont\", palette=\"Reds\", title = \"2023\")+\n  tm_shape(AccNations2022) + tm_dots(col = \"black\", size = 0.01)+\n  tm_shape(ArrDesNations) + tm_borders(col = \"black\", lwd = 2)+\n  tm_scale_bar(breaks  = c(0, 1, 2))+tm_layout(frame = FALSE)\ntmap_arrange(Carte1, Carte2, Carte3, Carte4,\n             ncol = 2, nrow = 2)\n```\n\n::: {.cell-output-display}\n![Comparaison des résultats de la KDE pour différentes années](03-MethodesRepartitionPonctuelle_files/figure-pdf/fig-CartoTemporelleKernels-1.pdf){#fig-CartoTemporelleKernels fig-align='center' fig-pos='H' width=85%}\n:::\n:::\n\n\n\n\n\n\n### Densité spatio-temporelle dans une maille régulière {#sec-0343}\n\n#### Description de la méthode STKDE {#sec-03431}\n\nDans les sections précédentes, nous avons vu que l'analyse de densité dans une maille régulière avec la méthode KDE consiste à répartir la masse des évènements étudiés dans un certain rayon d'influence (*bandwidth*) autour de chaque évènement selon une fonction décroissante (*kernel*).\n\nCette méthode peut être étendue assez facilement au contexte spatio-temporel. En effet, lorsque les évènements étudiés sont caractérisés par une date d'occurrence, il est possible de répartir leur masse à la fois dans l'espace et dans le temps. Plus exactement, il s'agit d'un kernel bivarié comprenant une *bandwidth* spatiale et une *bandwidth* temporelle. La densité locale est alors estimée avec le produit de la densité spatiale et de la densité temporelle de chaque évènement (@eq-STKDEDensity).\n\n$$\n\\lambda(s) = \\sum_{i=1}^n \\frac{1}{\\pi bw_s^2 \\times bw_t} k\\biggl(\\frac{d_{si}}{bw_s}\\biggl) k\\biggl(\\frac{t_{si}}{bw_t}\\biggl)\\text{ avec }\n$$ {#eq-STKDEDensity}\n\n-   $bw_t$ et $bw_s$ les rayons d'influence (*bandwidth*) temporel et spatial.\n-   $t_{si}$ et $d_{si}$ les distances temporelles et spatiales entre l'évènement *i* et un point dans l'espace et le temps *s*.\n-   $k$, fonction *kernel*.\n\nLa @fig-ExampleSTKDE illustre le principe de la STKDE (*Space-Time Kernel Density Estimatation*). Un évènement a lieu à un moment spécifique et en un lieu spécifique. Plus nous sommes proches de l'évènement dans le temps et dans l'espace, plus la densité est élevée. Hors du *bandwidth* dans le temps ou dans l'espace, la densité est nulle.\n\n![Visualisation de la STKDE](images/Chap03/SpaceTimeDensity-01.png){#fig-ExampleSTKDE width=\"90%\" fig-align=\"center\"}\n\nUne représentation particulièrement efficace de la STKDE est une carte animée permettant de visualiser l'évolution spatiale de la densité dans le temps. À la @fig-ExampleSTKDEanim, nous visualisons la densité spatio-temporelle produite par deux évènements ayant eu lieu à des moments et des localisations différentes.\n\n\n\n\n\n\n::: {.cell}\n\n:::\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![Visualisation animée de la STKDE](images/Chap03/animated_STKDE.jpg){#fig-ExampleSTKDEanim fig-align='center' width=50%}\n:::\n:::\n\n\n\n\n\n\nEn résumé, la seule différence avec la KDE et la STKDE est que cette dernière nécessite de déterminer une *bandwidth* temporelle (en plus de la *bandwidth* spatiale).\n\n#### Mise en œuvre de la STKDE dans R {#sec-03432}\n\nPour mettre en œuvre la STKDE sur les données de collisions de la ville de Sherbrooke, nous utilisons le *package* `sparr` [@Packagesparr]. À la @fig-timeCollisions, nous visualisons aisément les périodes durant lesquelles les accidents ont été les plus nombreux.\n\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(spatstat)\nlibrary(terra)\nlibrary(gifski)\nlibrary(sf)\nlibrary(tmap)\nlibrary(ggplot2)\nlibrary(sparr)\nlibrary(lubridate)\nlibrary(classInt)\nlibrary(viridis)\n\nroutes <- st_read('data/chap01/shp/Segments_de_rue.shp', quiet = TRUE)\ncollisions <- st_read('data/chap04/DataAccidentsSherb.shp', quiet = TRUE)\n## Reprojection dans le même système\nroutes <- st_transform(routes, 2949)\ncollisions <- st_transform(collisions, 2949)\n## Visualisation de la densité temporelle\ncollisions$dt <- as_date(collisions$DATEINCIDE)\ncollisions$dt_num <- as.numeric(collisions$dt - min(collisions$dt))\nggplot(collisions, aes(x=dt)) + \n  geom_density(bw = 'sj', color = \"blue\", lwd = 1) + \n  labs(y= \"Densité\", x = \"Date\")+\n  scale_x_date(date_breaks = \"6 months\", date_labels =  \"%b %Y\")+\n  theme_bw()\n```\n\n::: {.cell-output-display}\n![Distribution temporelle de la densité des accidents](03-MethodesRepartitionPonctuelle_files/figure-pdf/fig-timeCollisions-1.pdf){#fig-timeCollisions fig-align='center' fig-pos='H' width=85%}\n:::\n:::\n\n\n\n\n\n\nPour calculer la STKDE, nous devons déterminer les valeurs des deux *bandwidths*, réalisé ici avec une approche dite de validation croisée par maximum de vraisemblance.\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## Préparation des données de collisions\nfenetre <- as.owin(st_buffer(collisions,500))\nXY <- st_coordinates(collisions)\ncollisions.ppp <- ppp(x = XY[,1],\n                    y = XY[,2],\n                    window = fenetre, check = T)\n## Estimation des deux meilleures bandwidths\nscores_bw <- LIK.spattemp(collisions.ppp, \n                          tt = collisions$dt_num,\n                          tlim = c(0,1100),\n                          parallelise = NA,verbose = FALSE)\nprint(scores_bw)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n       h   lambda \n736.8287 147.4328 \n```\n\n\n:::\n:::\n\n\n\n\n\n\nLes valeurs optimales obtenues avec l'approche dite de validation croisée par maximum de vraisemblance sont de 736 mètres pour la *bandwidth* spatiale et 147 jours pour la *bandwidth* temporelle. Cette dernière est vraisemblablement trop grande. Par conséquent, nous utilisons des *bandwidths* de 750 mètres et 14 jours. Notez que les valeurs de densité sont multipliées par 10 000, car leur étalement dans l'espace et le temps conduit à des valeurs trop petites pour le *package* `tmap`. Les résultats sont présentés sous la forme d'une animation à la @fig-spacetimemapSherb.\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Calcul des valeurs de densités\ndens_vals <- spattemp.density(collisions.ppp,\n                              h = 750,\n                              lambda = 14,\n                              tt = collisions$dt_num,\n                              tlim = c(0,1100),\n                              sres = 500,\n                              tres = 150, verbose = FALSE)\n\n## Extraction des rasters à chaque période\nall_rasts <- lapply(dens_vals$z, function(x){\n  my_rast <- terra::rast(x) * 10000 # petit ajustement pour la carto\n  vals <- terra::values(my_rast)\n  vals <- ifelse(is.na(vals), 0, vals)\n  terra::values(my_rast) <- vals\n  terra::crs(my_rast) <- 'epsg:32188'\n  return(my_rast)\n})\n## Extraction des valeurs pour créer une échelle commune de couleur\nall_densities <- do.call(c, lapply(all_rasts, function(x){\n  sample(terra::values(x),size = 100,replace = FALSE)\n}))\ncolor_breaks <- classIntervals(all_densities, n = 10, style = \"kmeans\")\n## Préparation des dates\ntimestamps <- round(as.numeric(names(dens_vals$z)))\ntime_frames <- min(collisions$dt) + days(timestamps)\n## Compilation des cartes\nall_maps <- lapply(1:length(time_frames), function(i){\n  tm_shape(all_rasts[[i]]) +\n    tm_raster(breaks = color_breaks$brks, palette = viridis(10)) +\n    tm_layout(legend.show = FALSE, frame = FALSE, title = time_frames[[i]])\n})\n\n# Création d'une animation pour produire la carte animée\ntmap_animation(all_maps, filename = \"images/Chap03/animated_STKDE_sherbrooke.gif\", \n               width = 500, height = 500, dpi = 150, delay = 25)\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![Distribution spatio-temporelle de la densité des accidents](images/Chap03/animated_STKDE_sherbrooke.jpg){#fig-spacetimemapSherb fig-align='center' width=50%}\n:::\n:::\n\n\n\n\n\n\n\n## Quiz de révision du chapitre {#sec-035}\n\n\n\n\n\n\n**Questions**\n\n* **Quelle est la différence entre le centre moyen et le point central?**\n\t+ Le centre moyen peut être pondéré contrairement au point central.\n\t+ Le point central est un point qui fait partie du semis de points initial.\n\n\tRelisez au besoin la [section @sec-03112].\n\n* **Associer la distance standard à chacun des trois semis de points suivants :**\n\n\t ![](images/quiz/Chap03_q02.png){width=50%}\n\n\t+ A = 219, B = 347, C = 685\n\t+ A = 685, B = 219, C = 347\n\t+ A = 685, B = 347, C = 219\n\n\tRelisez au besoin la [section @sec-0312].\n\n* **Quelles sont les quatre principales manières de représenter graphiquement la dispersion d'un semis de points?**\n\t+ Enveloppe convexe\n\t+ Centre moyen et point central\n\t+ Rectangle construit avec les déviations standards des X et des Y\n\t+ Distance standard\n\t+ Ellipse de déviation de distance standard\n\n\tRelisez au besoin la [section @sec-03131].\n\n* **Quelles sont les trois principales distributions d'un semis de points?**\n\t+ Distribution dispersée\n\t+ Distribution aléatoire\n\t+ Distribution concentrée\n\t+ Distribution normale\n\n\tRelisez au besoin la [section @sec-033].\n\n* **À la lecture des résultats de la méthode du plus proche voisin, quelle année a la distribution spatiale la plus concentrée?**\n\n\t ![](images/quiz/Chap03_q05.jpg){width=50%}\n\n\t+ 2019\n\t+ 2020\n\t+ 2021\n\t+ 2022\n\n\tRelisez au besoin la [section @sec-0331].\n\n* **En analyse des quadrats, quelles sont les trois principales formes utilisées?**\n\t+ Triangle\n\t+ Carré\n\t+ Hexagone\n\t+ Cercle\n\n\tRelisez au besoin la [section @sec-03231].\n\n* **Quel est le paramètre influençant le plus les résultats de la méthode KDE?**\n\t+ La fonction kernel utilisée\n\t+ La taille du rayon d'influence\n\n\tRelisez au besoin la [section @sec-03421].\n\n* **Quelles sont les principales fonctions kernel?**\n\t+ Gaussienne\n\t+ Quadratique\n\t+ Uniforme\n\t+ Manhattan\n\t+ Epanechnikov\n\n\tRelisez au besoin la [section @sec-03421].\n\n\n**Réponses**\n\n * Quelle est la différence entre le centre moyen et le point central?\n\t+ Le point central est un point qui fait partie du semis de points initial.\n * Associer la distance standard à chacun des trois semis de points suivants :\n\t+ A = 685, B = 219, C = 347\n * Quelles sont les quatre principales manières de représenter graphiquement la dispersion d'un semis de points?\n\t+ Enveloppe convexe\n\t+ Rectangle construit avec les déviations standards des X et des Y\n\t+ Distance standard\n\t+ Ellipse de déviation de distance standard\n * Quelles sont les trois principales distributions d'un semis de points?\n\t+ Distribution dispersée\n\t+ Distribution aléatoire\n\t+ Distribution concentrée\n * À la lecture des résultats de la méthode du plus proche voisin, quelle année a la distribution spatiale la plus concentrée?\n\t+ 2020\n * En analyse des quadrats, quelles sont les trois principales formes utilisées?\n\t+ Carré\n\t+ Hexagone\n\t+ Cercle\n * Quel est le paramètre influençant le plus les résultats de la méthode KDE?\n\t+ La taille du rayon d'influence\n * Quelles sont les principales fonctions kernel?\n\t+ Gaussienne\n\t+ Quadratique\n\t+ Uniforme\n\t+ Epanechnikov\n\n\n\n\n\n\n## Exercices de révision {#sec-036}\n\n::: bloc_exercice\n::: bloc_exercice-header\n::: bloc_exercice-icon\n:::\n\n**Exercice 1.** Calcul du centre moyen et de la distance standard pour les accidents\n:::\n\n::: bloc_exercice-body\nComplétez le code ci-dessous.\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(sf)\nlibrary(tmap)\n## Importation des données \nArrondissements <-  st_read(dsn = \"data/chap03/Arrondissements.shp\", quiet=TRUE)\nIncidents <- st_read(dsn = \"data/chap03/IncidentsSecuritePublique.shp\", quiet=TRUE)\n## Changement de projection\nArrondissements <- st_transform(Arrondissements, crs = 3798) \nIncidents <- st_transform(Incidents, crs = 3798)\n## Couche pour les accidents\nAccidents <- subset(Incidents, Incidents$DESCRIPTIO %in% \n                      c(\"Accident avec blessés\", \"Accident mortel\"))\n## Coordonnées et projection cartographique\nxy <- À compléter\nProjCarto <- À compléter\n## Centre moyen\nCentreMoyen <- data.frame(À compléter)\nCentreMoyen <- st_as_sf(CentreMoyen, coords = c(\"X\", \"Y\"), crs = À compléter)\n# Distance standard combinée\nCentreMoyen$DS <- À compléter\nCercleDS <- À compléter\nhead(CercleDS)\n```\n:::\n\n\n\n\n\n\nCorrection à la [section @sec-12031].\n:::\n:::\n\n::: bloc_exercice\n::: bloc_exercice-header\n::: bloc_exercice-icon\n:::\n\n**Exercice 2.** Calcul et cartographie de la densité des accidents dans un maillage irrégulier\n:::\n\n::: bloc_exercice-body\nPour l'année 2021, complétez le code ci-dessous.\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(sf)\nlibrary(tmap)\n## Importation des données \nSR <- st_read(dsn = \"data/chap03/Recen2021Sherbrooke.gpkg\",\n              layer = \"DR_SherbSRDonnees2021\", quiet=TRUE)\n## Couche pour les accidents pour l'année 2021\nAcc2021 <- subset(Incidents, Incidents$DESCRIPTIO %in% \n                    c(\"Accident avec blessés\", \"Accident mortel\")\n                  & ANNEE==2021)\n## Nous nous assurons que les deux couches ont la même projection cartographique\nSR <- st_transform(SR, st_crs(Acc2021))\n## Calcul du nombre d'incidents par SR \nSR$Acc2021 <- À compléter\n## Calcul du nombre de méfaits pour 1000 habitants\nSR$DensiteMAcc2021Hab <- À compléter\n## Cartographie\ntm_shape(SR)+\n  tm_polygons(col= À compléter, style=\"pretty\", \n              title=\"Nombre pour 1000 habitants\",\n              border.col = \"black\", lwd = 1)+\n  tm_bubbles(size = À compléter, border.col = \"black\", alpha = .5,\n             col = \"aquamarine3\", title.size = \"Nombre\", scale = 1.5)+ \n  tm_layout(frame = FALSE)+tm_scale_bar(text.size = .5, c(0, 5, 10))\n```\n:::\n\n\n\n\n\n\nCorrection à la [section @sec-12032].\n:::\n:::\n\n::: bloc_exercice\n::: bloc_exercice-header\n::: bloc_exercice-icon\n:::\n\n**Exercice 3.** Calcul et cartographie de la densité des accidents dans un maillage régulier\n:::\n\n::: bloc_exercice-body\nPour l'année 2021, complétez le code ci-dessous.\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(sf)\nlibrary(spatstat)\nlibrary(tmap)\nlibrary(terra)\n\n## Importation des données \nArrondissements <-  st_read(dsn = \"data/chap03/Arrondissements.shp\", quiet=TRUE)\nIncidents <- st_read(dsn = \"data/chap03/IncidentsSecuritePublique.shp\", quiet=TRUE)\n## Changement de projection\nArrondissements <- st_transform(Arrondissements, crs = 3798) \nIncidents <- st_transform(Incidents, crs = 3798)\n## Couche pour les méfaits pour l'année 2021\nM2021 <- subset(Incidents, DESCRIPTIO == \"Méfait\" & ANNEE==2021)\n## Pour accélérer les calculs, nous retenons uniquement l'arrondissement des Nations\n# Couche pour l'arrondissement des Nations\nArrDesNations <- subset(Arrondissements, NOM == \"Arrondissement des Nations\")\n# Sélection des accidents localisés dans l'arrondissement Des Nations\nRequeteSpatiale <- st_intersects(M2021, ArrDesNations, sparse = FALSE)\nM2021$Nations <- RequeteSpatiale[, 1]\nM2021Nations <- subset(M2021, M2021$Nations == TRUE)\n\n## Conversion des données sf dans le format de spatstat\n# la fonction as.owin est utilisée pour définir la fenêtre de travail\nfenetre <- à complétér\n## Conversion des points au format ppp pour les différentes années\nM2021.ppp <- à complétér\n\n## Kernel quadratique avec un rayon de 500 mètres et une taille de pixel de 50 mètres\nkdeQ <- density.ppp(M2021.ppp, sigma=500, eps=50, kernel=\"quartic\")\n## Conversion en raster\nRkdeQ <- terra::rast(kdeQ)*1000000\n## Projection cartographique\ncrs(RkdeQ) <- \"epsg:3857\"\n## Visualisation des résultats\ntmap_mode(\"plot\")\n  À compléter\n```\n:::\n\n\n\n\n\n\nCorrection à la [section @sec-12033].\n:::\n:::\n",
    "supporting": [
      "03-MethodesRepartitionPonctuelle_files\\figure-pdf"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {
      "knitr": [
        "{\"type\":\"list\",\"attributes\":{},\"value\":[]}"
      ]
    },
    "preserve": null,
    "postProcess": false
  }
}